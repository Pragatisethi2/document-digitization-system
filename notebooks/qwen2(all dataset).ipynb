{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T15:02:00.117085Z",
     "iopub.status.busy": "2025-05-20T15:02:00.116814Z",
     "iopub.status.idle": "2025-05-20T15:02:06.431624Z",
     "shell.execute_reply": "2025-05-20T15:02:06.430793Z",
     "shell.execute_reply.started": "2025-05-20T15:02:00.117063Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge-score) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge-score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge-score) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge-score) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge-score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge-score) (2024.2.0)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=c4e4dc2c6569ceee4a81bf33b0b5410fcd1129783720e7e5344d94f86bb1c5d4\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: rouge-score\n",
      "Successfully installed rouge-score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge-score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FORM DATASTET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T15:02:09.738185Z",
     "iopub.status.busy": "2025-05-20T15:02:09.737652Z",
     "iopub.status.idle": "2025-05-20T15:38:35.372232Z",
     "shell.execute_reply": "2025-05-20T15:38:35.371592Z",
     "shell.execute_reply.started": "2025-05-20T15:02:09.738153Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-20 15:02:23.128358: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747753343.361137      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747753343.427736      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 images to process\n",
      "Loading Qwen-2VL model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728bd81a105d4de4b841a8ae4cb2db00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 1/50: 0000971160.png\n",
      "Converting L image to RGB\n",
      "Processing image 2/50: 0000989556.png\n",
      "Converting L image to RGB\n",
      "Processing image 3/50: 0000990274.png\n",
      "Converting L image to RGB\n",
      "Processing image 4/50: 0000999294.png\n",
      "Converting L image to RGB\n",
      "Processing image 5/50: 0001118259.png\n",
      "Converting L image to RGB\n",
      "Processing image 6/50: 0001123541.png\n",
      "Converting L image to RGB\n",
      "Processing image 7/50: 0001129658.png\n",
      "Converting L image to RGB\n",
      "Processing image 8/50: 0001209043.png\n",
      "Converting L image to RGB\n",
      "Processing image 9/50: 0001239897.png\n",
      "Converting L image to RGB\n",
      "Processing image 10/50: 0001438955.png\n",
      "Converting L image to RGB\n",
      "Processing image 11/50: 0001456787.png\n",
      "Converting L image to RGB\n",
      "Processing image 12/50: 0001463282.png\n",
      "Converting L image to RGB\n",
      "Processing image 13/50: 0001463448.png\n",
      "Converting L image to RGB\n",
      "Processing image 14/50: 0001476912.png\n",
      "Converting L image to RGB\n",
      "Processing image 15/50: 0001477983.png\n",
      "Converting L image to RGB\n",
      "Processing image 16/50: 0001485288.png\n",
      "Converting L image to RGB\n",
      "Processing image 17/50: 00040534.png\n",
      "Converting L image to RGB\n",
      "Processing image 18/50: 00070353.png\n",
      "Converting L image to RGB\n",
      "Processing image 19/50: 00093726.png\n",
      "Converting L image to RGB\n",
      "Processing image 20/50: 0011505151.png\n",
      "Converting L image to RGB\n",
      "Processing image 21/50: 0011838621.png\n",
      "Converting L image to RGB\n",
      "Processing image 22/50: 0011845203.png\n",
      "Converting L image to RGB\n",
      "Processing image 23/50: 0011856542.png\n",
      "Converting L image to RGB\n",
      "Processing image 24/50: 0011859695.png\n",
      "Converting L image to RGB\n",
      "Processing image 25/50: 0011899960.png\n",
      "Converting L image to RGB\n",
      "Processing image 26/50: 0011906503.png\n",
      "Converting L image to RGB\n",
      "Processing image 27/50: 0011973451.png\n",
      "Converting L image to RGB\n",
      "Processing image 28/50: 0011974919.png\n",
      "Converting L image to RGB\n",
      "Processing image 29/50: 0011976929.png\n",
      "Converting L image to RGB\n",
      "Processing image 30/50: 0012178355.png\n",
      "Converting L image to RGB\n",
      "Processing image 31/50: 0012199830.png\n",
      "Converting L image to RGB\n",
      "Processing image 32/50: 0012529284.png\n",
      "Converting L image to RGB\n",
      "Processing image 33/50: 0012529295.png\n",
      "Converting L image to RGB\n",
      "Processing image 34/50: 0012602424.png\n",
      "Converting L image to RGB\n",
      "Processing image 35/50: 0012947358.png\n",
      "Converting L image to RGB\n",
      "Processing image 36/50: 0013255595.png\n",
      "Converting L image to RGB\n",
      "Processing image 37/50: 00283813.png\n",
      "Converting L image to RGB\n",
      "Processing image 38/50: 0030031163.png\n",
      "Converting L image to RGB\n",
      "Processing image 39/50: 0030041455.png\n",
      "Converting L image to RGB\n",
      "Processing image 40/50: 0060000813.png\n",
      "Converting L image to RGB\n",
      "Processing image 41/50: 0060007216.png\n",
      "Converting L image to RGB\n",
      "Processing image 42/50: 0060024314.png\n",
      "Converting L image to RGB\n",
      "Processing image 43/50: 0060025670.png\n",
      "Converting L image to RGB\n",
      "Processing image 44/50: 0060029036.png\n",
      "Converting L image to RGB\n",
      "Processing image 45/50: 0060036622.png\n",
      "Converting L image to RGB\n",
      "Processing image 46/50: 0060068489.png\n",
      "Converting L image to RGB\n",
      "Processing image 47/50: 0060077689.png\n",
      "Converting L image to RGB\n",
      "Processing image 48/50: 0060080406.png\n",
      "Converting L image to RGB\n",
      "Processing image 49/50: 0060091229.png\n",
      "Converting L image to RGB\n",
      "Processing image 50/50: 0060094595.png\n",
      "Converting L image to RGB\n",
      "Results saved to qwen_ocr_results.csv\n",
      "Loaded 50 OCR results\n",
      "Calculated ROUGE for 0000971160.png\n",
      "Calculated ROUGE for 0000989556.png\n",
      "Calculated ROUGE for 0000990274.png\n",
      "Calculated ROUGE for 0000999294.png\n",
      "Calculated ROUGE for 0001118259.png\n",
      "Calculated ROUGE for 0001123541.png\n",
      "Calculated ROUGE for 0001129658.png\n",
      "Calculated ROUGE for 0001209043.png\n",
      "Calculated ROUGE for 0001239897.png\n",
      "Calculated ROUGE for 0001438955.png\n",
      "Calculated ROUGE for 0001456787.png\n",
      "Calculated ROUGE for 0001463282.png\n",
      "Calculated ROUGE for 0001463448.png\n",
      "Calculated ROUGE for 0001476912.png\n",
      "Calculated ROUGE for 0001477983.png\n",
      "Calculated ROUGE for 0001485288.png\n",
      "Calculated ROUGE for 00040534.png\n",
      "Calculated ROUGE for 00070353.png\n",
      "Calculated ROUGE for 00093726.png\n",
      "Calculated ROUGE for 0011505151.png\n",
      "Calculated ROUGE for 0011838621.png\n",
      "Calculated ROUGE for 0011845203.png\n",
      "Calculated ROUGE for 0011856542.png\n",
      "Calculated ROUGE for 0011859695.png\n",
      "Calculated ROUGE for 0011899960.png\n",
      "Calculated ROUGE for 0011906503.png\n",
      "Calculated ROUGE for 0011973451.png\n",
      "Calculated ROUGE for 0011974919.png\n",
      "Calculated ROUGE for 0011976929.png\n",
      "Calculated ROUGE for 0012178355.png\n",
      "Calculated ROUGE for 0012199830.png\n",
      "Calculated ROUGE for 0012529284.png\n",
      "Calculated ROUGE for 0012529295.png\n",
      "Calculated ROUGE for 0012602424.png\n",
      "Calculated ROUGE for 0012947358.png\n",
      "Calculated ROUGE for 0013255595.png\n",
      "Calculated ROUGE for 00283813.png\n",
      "Calculated ROUGE for 0030031163.png\n",
      "Calculated ROUGE for 0030041455.png\n",
      "Calculated ROUGE for 0060000813.png\n",
      "Calculated ROUGE for 0060007216.png\n",
      "Calculated ROUGE for 0060024314.png\n",
      "Calculated ROUGE for 0060025670.png\n",
      "Calculated ROUGE for 0060029036.png\n",
      "Calculated ROUGE for 0060036622.png\n",
      "Calculated ROUGE for 0060068489.png\n",
      "Calculated ROUGE for 0060077689.png\n",
      "Calculated ROUGE for 0060080406.png\n",
      "Calculated ROUGE for 0060091229.png\n",
      "Calculated ROUGE for 0060094595.png\n",
      "\n",
      "Average ROUGE Scores for Qwen-2VL:\n",
      "model: Qwen-2VL\n",
      "avg_rouge1_precision: 0.8114\n",
      "avg_rouge1_recall: 0.8567\n",
      "avg_rouge1_f1: 0.8256\n",
      "avg_rouge2_precision: 0.6107\n",
      "avg_rouge2_recall: 0.6547\n",
      "avg_rouge2_f1: 0.6285\n",
      "avg_rougeL_precision: 0.5955\n",
      "avg_rougeL_recall: 0.6332\n",
      "avg_rougeL_f1: 0.6079\n",
      "num_images_processed: 50\n",
      "\n",
      "Top 5 images by ROUGE-L F1 score:\n",
      "1. 0030031163.png - ROUGE-L F1: 0.9141\n",
      "2. 0060036622.png - ROUGE-L F1: 0.8687\n",
      "3. 0001463448.png - ROUGE-L F1: 0.8683\n",
      "4. 0000971160.png - ROUGE-L F1: 0.8601\n",
      "5. 0030041455.png - ROUGE-L F1: 0.8592\n",
      "\n",
      "Bottom 5 images by ROUGE-L F1 score:\n",
      "1. 0000999294.png - ROUGE-L F1: 0.3295\n",
      "2. 0001438955.png - ROUGE-L F1: 0.3221\n",
      "3. 0012529295.png - ROUGE-L F1: 0.0226\n",
      "4. 0011838621.png - ROUGE-L F1: 0.0203\n",
      "5. 0011856542.png - ROUGE-L F1: 0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "import re\n",
    "import glob\n",
    "from PIL import Image, ImageEnhance\n",
    "import torch\n",
    "from transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n",
    "import time\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Configuration\n",
    "class CFG:\n",
    "    model_name = \"/kaggle/input/qwen2-vl/transformers/7b-instruct/1\"  # Update this path to your model location\n",
    "    image_dir = '/kaggle/input/form-ocr-dataset-1/training_data/images'  # Update to your image directory\n",
    "    annotation_dir = '/kaggle/input/form-ocr-dataset-1/training_data/annotations'  # Update to your annotation directory\n",
    "    num_images = 50\n",
    "    output_csv = 'qwen_ocr_results.csv'\n",
    "    enhance_contrast = True  # Set to True to enhance image contrast\n",
    "    contrast_factor = 2.0  # Contrast enhancement factor\n",
    "\n",
    "# Load model only once\n",
    "def build_model():\n",
    "    print('Loading Qwen-2VL model...')\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(CFG.model_name)\n",
    "    \n",
    "    model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "        CFG.model_name,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    return processor, model\n",
    "\n",
    "# Process single image using Qwen-2VL\n",
    "def process_image(image_path, processor, model):\n",
    "    try:\n",
    "        # Load and preprocess image\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # Convert to RGB if not already\n",
    "        if image.mode != 'RGB':\n",
    "            print(f\"Converting {image.mode} image to RGB\")\n",
    "            image = image.convert('RGB')\n",
    "        \n",
    "        # Enhance contrast if enabled\n",
    "        if CFG.enhance_contrast:\n",
    "            image = ImageEnhance.Contrast(image).enhance(CFG.contrast_factor)\n",
    "        \n",
    "        # Start timing\n",
    "        start_time = time.time()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "        \n",
    "        # Prepare input in the Qwen chat format\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\"},\n",
    "                    {\"type\": \"text\", \"text\": \"Extract all the text in this image.\"}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        inputs = processor(\n",
    "            text=processor.apply_chat_template(messages, add_generation_prompt=True),\n",
    "            images=[image],\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Move inputs to device\n",
    "        device = next(model.parameters()).device\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Generate text\n",
    "        output_ids = model.generate(**inputs, max_new_tokens=1024)\n",
    "        \n",
    "        # Decode output\n",
    "        extracted_text = processor.batch_decode(\n",
    "            output_ids, \n",
    "            skip_special_tokens=True, \n",
    "            clean_up_tokenization_spaces=True\n",
    "        )[0]\n",
    "        \n",
    "        # Get metrics\n",
    "        inference_time = time.time() - start_time\n",
    "        max_memory = torch.cuda.max_memory_allocated() / (1024 ** 2) if torch.cuda.is_available() else 0  # MB\n",
    "        \n",
    "        # Clean up\n",
    "        del inputs, output_ids\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        gc.collect()\n",
    "        \n",
    "        # Optional: display the image and extracted text (useful for debugging)\n",
    "        if False:  # Set to True if you want to see the images during processing\n",
    "            plt.figure(figsize=(10, 10))\n",
    "            plt.imshow(image)\n",
    "            plt.axis(\"off\")\n",
    "            plt.title(\"Processed Image\")\n",
    "            plt.show()\n",
    "            print(f\"Extracted Text: {extracted_text}\")\n",
    "        \n",
    "        return extracted_text, inference_time, max_memory\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {str(e)}\")\n",
    "        return None, None, None\n",
    "\n",
    "# Main processing function for OCR\n",
    "def process_ocr():\n",
    "    # Get images\n",
    "    all_images = sorted([\n",
    "        os.path.join(CFG.image_dir, f) \n",
    "        for f in os.listdir(CFG.image_dir) \n",
    "        if f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "    ])[:CFG.num_images]\n",
    "    \n",
    "    print(f\"Found {len(all_images)} images to process\")\n",
    "    \n",
    "    # Load model once\n",
    "    processor, model = build_model()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for idx, img_path in enumerate(all_images, 1):\n",
    "        img_filename = os.path.basename(img_path)\n",
    "        print(f\"Processing image {idx}/{len(all_images)}: {img_filename}\")\n",
    "        \n",
    "        ocr_text, inf_time, mem_usage = process_image(img_path, processor, model)\n",
    "        \n",
    "        results.append({\n",
    "            'image_id': img_filename,\n",
    "            'ocr_text': ocr_text,\n",
    "            'inference_time_sec': inf_time,\n",
    "            'gpu_memory_usage_mb': mem_usage\n",
    "        })\n",
    "    \n",
    "    # Save results\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(CFG.output_csv, index=False)\n",
    "    print(f\"Results saved to {CFG.output_csv}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to extract all text from annotation file\n",
    "def extract_text_from_annotation(annotation_file):\n",
    "    try:\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        \n",
    "        # Your annotation format has a list of text entries\n",
    "        all_texts = []\n",
    "        \n",
    "        # Extract text from each item in the list\n",
    "        if isinstance(data, list):\n",
    "            for item in data:\n",
    "                if 'text' in item:\n",
    "                    all_texts.append(item['text'])\n",
    "        # If the data is a dictionary with a list under a key like 'annotations'\n",
    "        elif isinstance(data, dict):\n",
    "            for key in data:\n",
    "                if isinstance(data[key], list):\n",
    "                    for item in data[key]:\n",
    "                        if isinstance(item, dict) and 'text' in item:\n",
    "                            all_texts.append(item['text'])\n",
    "        \n",
    "        # Join all the text pieces\n",
    "        return \" \".join(all_texts)\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from {annotation_file}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Function to clean text for ROUGE comparison\n",
    "def clean_text(text):\n",
    "    if text is None or text == \"None\":\n",
    "        return \"\"\n",
    "    # Remove extra whitespace, newlines and normalize\n",
    "    return re.sub(r'\\s+', ' ', str(text)).strip()\n",
    "\n",
    "# Main function to calculate ROUGE scores\n",
    "def calculate_rouge():\n",
    "    # Load OCR results\n",
    "    ocr_results_df = pd.read_csv(CFG.output_csv)\n",
    "    print(f\"Loaded {len(ocr_results_df)} OCR results\")\n",
    "    \n",
    "    # Initialize ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    rouge_scores = []\n",
    "    \n",
    "    # Process each image that has OCR results\n",
    "    for _, row in ocr_results_df.iterrows():\n",
    "        image_filename = row['image_id']\n",
    "        ocr_text = clean_text(row['ocr_text'])\n",
    "        \n",
    "        # Skip if OCR failed\n",
    "        if not ocr_text:\n",
    "            print(f\"Skipping {image_filename} - No OCR text available\")\n",
    "            continue\n",
    "        \n",
    "        # Find corresponding annotation file\n",
    "        base_name = os.path.splitext(image_filename)[0]\n",
    "        annotation_path = os.path.join(CFG.annotation_dir, f\"{base_name}.json\")\n",
    "        \n",
    "        if not os.path.exists(annotation_path):\n",
    "            print(f\"No annotation found for {image_filename}\")\n",
    "            continue\n",
    "        \n",
    "        # Extract text from annotation\n",
    "        ground_truth = extract_text_from_annotation(annotation_path)\n",
    "        ground_truth = clean_text(ground_truth)\n",
    "        \n",
    "        if not ground_truth:\n",
    "            print(f\"Empty ground truth for {image_filename}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate ROUGE scores\n",
    "        scores = scorer.score(ground_truth, ocr_text)\n",
    "        \n",
    "        rouge_scores.append({\n",
    "            'image_file': image_filename,\n",
    "            'rouge1_precision': scores['rouge1'].precision,\n",
    "            'rouge1_recall': scores['rouge1'].recall,\n",
    "            'rouge1_f1': scores['rouge1'].fmeasure,\n",
    "            'rouge2_precision': scores['rouge2'].precision,\n",
    "            'rouge2_recall': scores['rouge2'].recall,\n",
    "            'rouge2_f1': scores['rouge2'].fmeasure,\n",
    "            'rougeL_precision': scores['rougeL'].precision,\n",
    "            'rougeL_recall': scores['rougeL'].recall,\n",
    "            'rougeL_f1': scores['rougeL'].fmeasure,\n",
    "            'ground_truth_length': len(ground_truth),\n",
    "            'ocr_text_length': len(ocr_text),\n",
    "            'ground_truth': ground_truth[:500] + \"...\" if len(ground_truth) > 500 else ground_truth,\n",
    "            'ocr_text': ocr_text[:500] + \"...\" if len(ocr_text) > 500 else ocr_text\n",
    "        })\n",
    "        \n",
    "        print(f\"Calculated ROUGE for {image_filename}\")\n",
    "    \n",
    "    # Save ROUGE scores to JSON\n",
    "    with open('qwen_rouge_scores.json', 'w') as f:\n",
    "        json.dump(rouge_scores, f, indent=4)\n",
    "    \n",
    "    # Calculate and print average scores\n",
    "    if rouge_scores:\n",
    "        avg_scores = {\n",
    "            'model': 'Qwen-2VL',\n",
    "            'avg_rouge1_precision': np.mean([s['rouge1_precision'] for s in rouge_scores]),\n",
    "            'avg_rouge1_recall': np.mean([s['rouge1_recall'] for s in rouge_scores]),\n",
    "            'avg_rouge1_f1': np.mean([s['rouge1_f1'] for s in rouge_scores]),\n",
    "            'avg_rouge2_precision': np.mean([s['rouge2_precision'] for s in rouge_scores]),\n",
    "            'avg_rouge2_recall': np.mean([s['rouge2_recall'] for s in rouge_scores]),\n",
    "            'avg_rouge2_f1': np.mean([s['rouge2_f1'] for s in rouge_scores]),\n",
    "            'avg_rougeL_precision': np.mean([s['rougeL_precision'] for s in rouge_scores]),\n",
    "            'avg_rougeL_recall': np.mean([s['rougeL_recall'] for s in rouge_scores]),\n",
    "            'avg_rougeL_f1': np.mean([s['rougeL_f1'] for s in rouge_scores]),\n",
    "            'num_images_processed': len(rouge_scores)\n",
    "        }\n",
    "        \n",
    "        print(\"\\nAverage ROUGE Scores for Qwen-2VL:\")\n",
    "        for metric, value in avg_scores.items():\n",
    "            if isinstance(value, float):\n",
    "                print(f\"{metric}: {value:.4f}\")\n",
    "            else:\n",
    "                print(f\"{metric}: {value}\")\n",
    "        \n",
    "        # Save summary\n",
    "        with open('qwen_rouge_scores_summary.json', 'w') as f:\n",
    "            json.dump(avg_scores, f, indent=4)\n",
    "        \n",
    "        # Create sorted lists for best/worst performing images\n",
    "        sorted_by_f1 = sorted(rouge_scores, key=lambda x: x['rougeL_f1'], reverse=True)\n",
    "        \n",
    "        print(\"\\nTop 5 images by ROUGE-L F1 score:\")\n",
    "        for i, score in enumerate(sorted_by_f1[:5]):\n",
    "            print(f\"{i+1}. {score['image_file']} - ROUGE-L F1: {score['rougeL_f1']:.4f}\")\n",
    "        \n",
    "        print(\"\\nBottom 5 images by ROUGE-L F1 score:\")\n",
    "        for i, score in enumerate(sorted_by_f1[-5:]):\n",
    "            print(f\"{i+1}. {score['image_file']} - ROUGE-L F1: {score['rougeL_f1']:.4f}\")\n",
    "        \n",
    "        return avg_scores\n",
    "    else:\n",
    "        print(\"No ROUGE scores calculated. Check your OCR results and annotation files.\")\n",
    "        return None\n",
    "\n",
    "# Compare results between Florence and Qwen models\n",
    "def compare_models():\n",
    "    try:\n",
    "        # Load Florence results\n",
    "        with open('rouge_scores_summary.json', 'r') as f:\n",
    "            florence_scores = json.load(f)\n",
    "        \n",
    "        # Load Qwen results\n",
    "        with open('qwen_rouge_scores_summary.json', 'r') as f:\n",
    "            qwen_scores = json.load(f)\n",
    "        \n",
    "        # Add model names\n",
    "        florence_scores['model'] = 'Florence-2'\n",
    "        \n",
    "        # Print comparison\n",
    "        print(\"\\n===== MODEL COMPARISON =====\")\n",
    "        metrics = [\n",
    "            'avg_rouge1_precision', 'avg_rouge1_recall', 'avg_rouge1_f1',\n",
    "            'avg_rouge2_precision', 'avg_rouge2_recall', 'avg_rouge2_f1',\n",
    "            'avg_rougeL_precision', 'avg_rougeL_recall', 'avg_rougeL_f1'\n",
    "        ]\n",
    "        \n",
    "        print(f\"{'Metric':<25} {'Florence-2':<15} {'Qwen-2VL':<15} {'Difference':<15}\")\n",
    "        print('-' * 70)\n",
    "        \n",
    "        for metric in metrics:\n",
    "            florence_val = florence_scores.get(metric, 0)\n",
    "            qwen_val = qwen_scores.get(metric, 0)\n",
    "            diff = qwen_val - florence_val\n",
    "            diff_str = f\"{diff:.4f} ({'+' if diff > 0 else ''}{diff/florence_val*100:.2f}%)\" if florence_val else \"N/A\"\n",
    "            \n",
    "            print(f\"{metric:<25} {florence_val:.4f} {qwen_val:.4f} {diff_str:<15}\")\n",
    "        \n",
    "        # Save comparison\n",
    "        comparison = {\n",
    "            'florence': florence_scores,\n",
    "            'qwen': qwen_scores,\n",
    "            'metrics_compared': metrics,\n",
    "            'differences': {metric: qwen_scores.get(metric, 0) - florence_scores.get(metric, 0) for metric in metrics}\n",
    "        }\n",
    "        \n",
    "        with open('model_comparison.json', 'w') as f:\n",
    "            json.dump(comparison, f, indent=4)\n",
    "            \n",
    "        print(\"\\nComparison saved to model_comparison.json\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error comparing models: {e}\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Process images with OCR using Qwen model\n",
    "    process_ocr()\n",
    "    \n",
    "    # Calculate ROUGE scores\n",
    "    calculate_rouge()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RECEIPTS DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T00:35:03.827982Z",
     "iopub.status.busy": "2025-05-21T00:35:03.827699Z",
     "iopub.status.idle": "2025-05-21T00:53:28.182448Z",
     "shell.execute_reply": "2025-05-21T00:53:28.181737Z",
     "shell.execute_reply.started": "2025-05-21T00:35:03.827960Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=afb0789f9f775a639dc1953f46430a5d9843ed9e7912e46b998376fb2c980e68\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n",
      "Loaded annotations for 20 images\n",
      "\n",
      "Loading model from: /kaggle/input/qwen2-vl/transformers/7b-instruct/1\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849ff4d32ae34ceca2648d8314871fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on device: cuda:0\n",
      "Processing 20 images\n",
      "\n",
      "Processing image 0: 0.jpg\n",
      "Annotations: 5 boxes\n",
      "  shop: WALMART\n",
      "  total: TOTAL 5.11\n",
      "  item: FRAP 001200010451 F 5.48 N\n",
      "  ... (1 more) ...\n",
      "  date_time: 08/20/10 13:12:01\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.2975\n",
      "ROUGE-2: 0.2017\n",
      "ROUGE-L: 0.1818\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.2241\n",
      "  total: 0.0385\n",
      "  shop: 0.0194\n",
      "  date_time: 0.0385\n",
      "\n",
      "Processing image 1: 1.jpg\n",
      "Annotations: 21 boxes\n",
      "  total: TOTAL $38.68\n",
      "  item: MINI-PEARL TOMATOES.. 2.49\n",
      "  item: PKG SHREDDED MOZZARELLA LITE T 3.99\n",
      "  ... (17 more) ...\n",
      "  item: ORGANIC OLD FASHIONED OATMEAL 2.69\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.7500\n",
      "ROUGE-2: 0.6457\n",
      "ROUGE-L: 0.3594\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.7200\n",
      "  total: 0.0252\n",
      "  shop: 0.0252\n",
      "  date_time: 0.0252\n",
      "\n",
      "Processing image 10: 10.jpg\n",
      "Annotations: 17 boxes\n",
      "  item: SMOKED VIENNAS 500GR 33.99 A\n",
      "  shop: SPAR\n",
      "  total: TOTAL FOR 14 ITEMS 338.16\n",
      "  ... (13 more) ...\n",
      "  item: BLACK CAT SMOOTH 270GR 27.99 A\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.6255\n",
      "ROUGE-2: 0.5370\n",
      "ROUGE-L: 0.3707\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.5817\n",
      "  total: 0.0559\n",
      "  shop: 0.0114\n",
      "  date_time: 0.0227\n",
      "\n",
      "Processing image 11: 11.jpg\n",
      "Annotations: 10 boxes\n",
      "  item: *WT PLUMS BLACK CV 2.15 B\n",
      "  item: * CAGE FREE ALL WHIT 3.69 B\n",
      "  shop: WHOLE FOODS MARKET\n",
      "  ... (6 more) ...\n",
      "  item: * California Harvest 2.69 B\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.1039\n",
      "ROUGE-2: 0.0533\n",
      "ROUGE-L: 0.1039\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.0541\n",
      "  shop: 0.1818\n",
      "\n",
      "Processing image 12: 12.jpg\n",
      "Annotations: 6 boxes\n",
      "  date_time: 10/20/07 13:48:43\n",
      "  item: TOOTHBRUSH 003500055500 0.96 X\n",
      "  item: WOMEN SLIPPE 009725614790 9.86 X\n",
      "  ... (2 more) ...\n",
      "  shop: WALMART\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.2154\n",
      "ROUGE-2: 0.1094\n",
      "ROUGE-L: 0.1385\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  date_time: 0.0354\n",
      "  total: 0.0354\n",
      "  item: 0.1440\n",
      "  shop: 0.0179\n",
      "\n",
      "Processing image 13: 13.jpg\n",
      "Annotations: 4 boxes\n",
      "  shop: Walmart\n",
      "  item: GIFT CARD 087458604333 50.00 0\n",
      "  date_time: 08/11/17 19:22:40\n",
      "  total: TOTAL 50.00\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.1475\n",
      "ROUGE-2: 0.0500\n",
      "ROUGE-L: 0.1148\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.0684\n",
      "  total: 0.0351\n",
      "  shop: 0.0177\n",
      "  date_time: 0.0351\n",
      "\n",
      "Processing image 14: 14.jpg\n",
      "Annotations: 9 boxes\n",
      "  total: TOTAL 26.60\n",
      "  item: VFUS ENG POM 005100024543 F 7.48 N\n",
      "  date_time: 05/04/17 19:54:18\n",
      "  ... (5 more) ...\n",
      "  item: 5OYD PKGTAPE 007535307841 1.12 X\n",
      "Running OCR extraction...\n",
      "Error during inference: CUDA out of memory. Tried to allocate 55.90 GiB. GPU 0 has a total capacity of 14.74 GiB of which 3.30 GiB is free. Process 2820 has 11.44 GiB memory in use. Of the allocated memory 11.21 GiB is allocated by PyTorch, and 114.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "OCR Result Preview:\n",
      "Error: CUDA out of memory. Tried to allocate 55.90 GiB. GPU 0 has a total capacity of 14.74 GiB of which 3.30 GiB is free. Process 2820 has 11.44 GiB ...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.0185\n",
      "ROUGE-2: 0.0000\n",
      "ROUGE-L: 0.0185\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.0000\n",
      "  total: 0.0274\n",
      "  shop: 0.0000\n",
      "  date_time: 0.0000\n",
      "\n",
      "Processing image 15: 15.jpg\n",
      "Annotations: 4 boxes\n",
      "  date_time: 07/22/16 20:53:11\n",
      "  shop: Walmart\n",
      "  item: DIABETES 068113131172H 12.58 N\n",
      "  total: TOTAL 12.58\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.1343\n",
      "ROUGE-2: 0.0758\n",
      "ROUGE-L: 0.1045\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  date_time: 0.0315\n",
      "  total: 0.0315\n",
      "  item: 0.0620\n",
      "  shop: 0.0159\n",
      "\n",
      "Processing image 16: 16.jpg\n",
      "Annotations: 6 boxes\n",
      "  date_time: 11/13/17 12:34:04\n",
      "  item: ASST 27 063099656595 4.88 X\n",
      "  shop: Walmart\n",
      "  ... (2 more) ...\n",
      "  total: TOTAL 23.19\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.2545\n",
      "ROUGE-2: 0.1840\n",
      "ROUGE-L: 0.1455\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  date_time: 0.0274\n",
      "  total: 0.0274\n",
      "  item: 0.2000\n",
      "  shop: 0.0138\n",
      "\n",
      "Processing image 17: 17.jpg\n",
      "Annotations: 16 boxes\n",
      "  total: TOTAL 38.68\n",
      "  item: CAMPARI TOM 073447501213 I 2.98 R\n",
      "  item: OSCRAN POM 003120027015 F 2.00 R\n",
      "  ... (12 more) ...\n",
      "  item: KFT SINGLES 002100061526 F 3.78 Y\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.5961\n",
      "ROUGE-2: 0.4506\n",
      "ROUGE-L: 0.2824\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.5680\n",
      "  total: 0.0231\n",
      "  shop: 0.0116\n",
      "  date_time: 0.0231\n",
      "\n",
      "Processing image 18: 18.jpg\n",
      "Annotations: 21 boxes\n",
      "  item: GV VEG OIL 007874221000 F 7.82 N\n",
      "  item: GREAT VALUE 007874206203 F 2.84 N\n",
      "  item: GAIN LFE 003700077007 6.97 X\n",
      "  ... (17 more) ...\n",
      "  total: TOTAL 86.35\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.5529\n",
      "ROUGE-2: 0.4260\n",
      "ROUGE-L: 0.2529\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.5313\n",
      "  total: 0.0169\n",
      "  shop: 0.0085\n",
      "  date_time: 0.0169\n",
      "\n",
      "Processing image 19: 19.jpg\n",
      "Annotations: 7 boxes\n",
      "  item: RED GRAPE 000000004023 KF 2.51 lb @ 1 lb /1.44 3.61 N\n",
      "  item: FIBER CHOICE 036926600094 12.94 N\n",
      "  item: GRILL COVER 471288396027 14.97 X\n",
      "  ... (3 more) ...\n",
      "  date_time: 10/16/21 11:22:45\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.3077\n",
      "ROUGE-2: 0.1702\n",
      "ROUGE-L: 0.1538\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.2464\n",
      "  total: 0.0351\n",
      "  shop: 0.0177\n",
      "  date_time: 0.0351\n",
      "\n",
      "Processing image 2: 2.jpg\n",
      "Annotations: 7 boxes\n",
      "  date_time: 10/18/20 11:30:46\n",
      "  total: TOTAL 49.90\n",
      "  item: M ATHLETICS 019104567781 24.97 X\n",
      "  ... (3 more) ...\n",
      "  item: OT 200Z TUM 081236803115 6.74 X\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.2907\n",
      "ROUGE-2: 0.2235\n",
      "ROUGE-L: 0.1512\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  date_time: 0.0272\n",
      "  total: 0.0272\n",
      "  item: 0.2515\n",
      "  shop: 0.0000\n",
      "\n",
      "Processing image 3: 3.jpg\n",
      "Annotations: 31 boxes\n",
      "  item: TATER TOTS 001312000026 F 2.96 O\n",
      "  item: HARD/PROV/DC 007874219410 F 2.68 0\n",
      "  item: STOK LT SWT 004127102774 F 4.42 T\n",
      "  ... (27 more) ...\n",
      "  item: TR HS FRM 4 002240062190 2.74 X\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.6745\n",
      "ROUGE-2: 0.4471\n",
      "ROUGE-L: 0.2576\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.6682\n",
      "  total: 0.0158\n",
      "  shop: 0.0079\n",
      "  date_time: 0.0000\n",
      "\n",
      "Processing image 4: 4.jpg\n",
      "Annotations: 4 boxes\n",
      "  item: SW HRO FGHTR 063050940732 6.94 T\n",
      "  shop: Walmart\n",
      "  date_time: 12/08/15 12:39:26\n",
      "  total: TOTAL 7.43\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.1504\n",
      "ROUGE-2: 0.0763\n",
      "ROUGE-L: 0.1053\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.0781\n",
      "  total: 0.0323\n",
      "  shop: 0.0163\n",
      "  date_time: 0.0323\n",
      "\n",
      "Processing image 5: 5.jpg\n",
      "Annotations: 6 boxes\n",
      "  item: KITL SEA SALT POT CHP $1.29 F\n",
      "  date_time: 02/10/2021 07:10 PM\n",
      "  total: Total : $28.28\n",
      "  ... (2 more) ...\n",
      "  item: BRAIDED BRIOCHE $6.99 F\n",
      "Running OCR extraction...\n",
      "Error during inference: CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 136.12 MiB is free. Process 2820 has 14.61 GiB memory in use. Of the allocated memory 14.35 GiB is allocated by PyTorch, and 130.10 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "OCR Result Preview:\n",
      "Error: CUDA out of memory. Tried to allocate 228.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 136.12 MiB is free. Process 2820 has 14.61 G...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.0202\n",
      "ROUGE-2: 0.0000\n",
      "ROUGE-L: 0.0202\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.0000\n",
      "  total: 0.0274\n",
      "  shop: 0.0000\n",
      "  date_time: 0.0000\n",
      "\n",
      "Processing image 6: 6.JPG\n",
      "Annotations: 8 boxes\n",
      "  date_time: 26/01/2015 16:14\n",
      "  item: 1 Woman 0\n",
      "  item: 1 Mineral Water 13, 000\n",
      "  ... (4 more) ...\n",
      "  item: 1 Ice Java Tea 16, 000\n",
      "Running OCR extraction...\n",
      "Error during inference: CUDA out of memory. Tried to allocate 5.73 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.08 GiB is free. Process 2820 has 13.66 GiB memory in use. Of the allocated memory 13.50 GiB is allocated by PyTorch, and 36.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
      "\n",
      "OCR Result Preview:\n",
      "Error: CUDA out of memory. Tried to allocate 5.73 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.08 GiB is free. Process 2820 has 13.66 GiB m...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.0388\n",
      "ROUGE-2: 0.0000\n",
      "ROUGE-L: 0.0388\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  date_time: 0.0000\n",
      "  total: 0.0270\n",
      "  item: 0.0211\n",
      "  shop: 0.0000\n",
      "\n",
      "Processing image 7: 7.jpg\n",
      "Annotations: 6 boxes\n",
      "  item: 6 WING PLATE 020108870398 3.98 P\n",
      "  date_time: 11/13/17 12:34:11\n",
      "  item: ASST 27 063099656595 4.88 X\n",
      "  ... (2 more) ...\n",
      "  total: TOTAL 23.19\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.2545\n",
      "ROUGE-2: 0.1963\n",
      "ROUGE-L: 0.2182\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.2000\n",
      "  total: 0.0274\n",
      "  shop: 0.0138\n",
      "  date_time: 0.0274\n",
      "\n",
      "Processing image 8: 8.jpg\n",
      "Annotations: 12 boxes\n",
      "  item: E 6333561 KS DICED TOM 6.49 E\n",
      "  item: 404609 ECO HALF PAN 6.49 A\n",
      "  shop: Costco WHOLESALE\n",
      "  ... (8 more) ...\n",
      "  total: **** TOTAL 89.13\n",
      "Running OCR extraction...\n",
      "Error during inference: image has wrong mode\n",
      "\n",
      "OCR Result Preview:\n",
      "Error: image has wrong mode\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.0000\n",
      "ROUGE-2: 0.0000\n",
      "ROUGE-L: 0.0000\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.0000\n",
      "  total: 0.0000\n",
      "  shop: 0.0000\n",
      "  date_time: 0.0000\n",
      "\n",
      "Processing image 9: 9.jpg\n",
      "Annotations: 34 boxes\n",
      "  shop: WinCo FOODS\n",
      "  item: SUNBEAN BUNS 7763306333 1.98 FS\n",
      "  item: EYE RND STK FP 20148200000 8.24 FS\n",
      "  ... (30 more) ...\n",
      "  item: DM PNAPL CHNKY 2400000164 1.96 FS 2 @ .98\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\n",
      "assistan...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.7094\n",
      "ROUGE-2: 0.5107\n",
      "ROUGE-L: 0.2607\n",
      "\n",
      "Per-label ROUGE-1 scores:\n",
      "  item: 0.6926\n",
      "  total: 0.0143\n",
      "  shop: 0.0143\n",
      "  date_time: 0.0143\n",
      "\n",
      "Evaluation complete. Results saved to ./qwen2_vl_results.json\n",
      "\n",
      "Average ROUGE Scores:\n",
      "  ROUGE-1: 0.3071\n",
      "  ROUGE-2: 0.2179\n",
      "  ROUGE-L: 0.1639\n",
      "Average inference time: 45.22 seconds\n",
      "\n",
      "Average ROUGE-1 per label:\n",
      "  item: 0.2656 (from 20 images)\n",
      "  total: 0.0275 (from 19 images)\n",
      "  shop: 0.0197 (from 20 images)\n",
      "  date_time: 0.0206 (from 19 images)\n",
      "\n",
      "Summary saved to qwen2_vl_summary.json\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from PIL import Image, ImageEnhance\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from rouge_score import rouge_scorer\n",
    "import re\n",
    "import subprocess\n",
    "import psutil\n",
    "\n",
    "# First, check and install required packages\n",
    "\n",
    "\n",
    "# Configuration class\n",
    "class CFG:\n",
    "    # Model\n",
    "    model_name = \"/kaggle/input/qwen2-vl/transformers/7b-instruct/1\"\n",
    "    max_tokens = 1024\n",
    "    contrast_factor = 2.0  # Enhance image contrast\n",
    "    \n",
    "    # Input data\n",
    "    image_root = '/kaggle/input/ocr-receipts-text-detection/images'\n",
    "    annotation_file = '/kaggle/input/ocr-receipts-text-detection/annotations.xml'\n",
    "    \n",
    "    # Output data\n",
    "    output_path = \"./qwen2_vl_results.json\"\n",
    "    \n",
    "    # Process all images by default\n",
    "    process_all = True\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage of the process\"\"\"\n",
    "    try:\n",
    "        process = psutil.Process(os.getpid())\n",
    "        memory_info = process.memory_info()\n",
    "        return {\n",
    "            'rss': memory_info.rss / (1024 * 1024),  # RSS in MB\n",
    "            'vms': memory_info.vms / (1024 * 1024)   # VMS in MB\n",
    "        }\n",
    "    except:\n",
    "        return {'rss': 0, 'vms': 0}\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"Build Qwen-2-VL model\"\"\"\n",
    "    print(f'\\nLoading model from: {CFG.model_name}\\n')\n",
    "    \n",
    "    # Import required modules\n",
    "    from transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n",
    "    \n",
    "    # Load model and processor\n",
    "    model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "        CFG.model_name,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(CFG.model_name)\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    print(f\"Model loaded successfully on device: {device}\")\n",
    "    \n",
    "    return processor, model\n",
    "\n",
    "def inference(image, model, processor):\n",
    "    \"\"\"Run inference with Qwen-2-VL model\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Enhance image contrast\n",
    "        enhanced_image = ImageEnhance.Contrast(image).enhance(CFG.contrast_factor).convert(\"RGB\")\n",
    "        \n",
    "        # Create messages for the model\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\"},\n",
    "                    {\"type\": \"text\", \"text\": \"Extract all the text from this receipt image. Include all items, prices, totals, and the store name.\"}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Process input\n",
    "        inputs = processor(\n",
    "            text=processor.apply_chat_template(messages, add_generation_prompt=True),\n",
    "            images=[enhanced_image],\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Move inputs to device\n",
    "        inputs = inputs.to(model.device)\n",
    "        \n",
    "        # Generate output\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(**inputs, max_new_tokens=CFG.max_tokens)\n",
    "        \n",
    "        # Decode output\n",
    "        extracted_text = processor.batch_decode(\n",
    "            output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )[0]\n",
    "        \n",
    "        # Extract only the model's response (remove prompts)\n",
    "        try:\n",
    "            # Check if there's an \"ASSISTANT:\" prefix in the output\n",
    "            if \"ASSISTANT:\" in extracted_text:\n",
    "                result = extracted_text.split(\"ASSISTANT:\", 1)[1].strip()\n",
    "            else:\n",
    "                result = extracted_text\n",
    "        except:\n",
    "            result = extracted_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during inference: {str(e)}\")\n",
    "        result = f\"Error: {str(e)}\"\n",
    "    \n",
    "    # Calculate runtime\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    # Clear CUDA cache\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Return results and metrics\n",
    "    return {\n",
    "        'result': result,\n",
    "        'inference_time': inference_time\n",
    "    }\n",
    "\n",
    "def parse_annotations(xml_file):\n",
    "    \"\"\"Parse annotations from XML file\"\"\"\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    annotations = {}\n",
    "    \n",
    "    # Process each image\n",
    "    for image in root.findall('.//image'):\n",
    "        img_id = int(image.get('id'))\n",
    "        img_name = image.get('name').split('/')[-1]\n",
    "        \n",
    "        # Extract annotations for this image\n",
    "        boxes = []\n",
    "        for box in image.findall('.//box'):\n",
    "            label_type = box.get('label')\n",
    "            text = box.find('.//attribute[@name=\"text\"]')\n",
    "            \n",
    "            if text is not None and text.text is not None:\n",
    "                boxes.append({\n",
    "                    'label': label_type,\n",
    "                    'text': text.text\n",
    "                })\n",
    "        \n",
    "        # Store annotations\n",
    "        annotations[img_id] = {\n",
    "            'filename': img_name,\n",
    "            'boxes': boxes\n",
    "        }\n",
    "    \n",
    "    return annotations\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text for better ROUGE matching\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Replace multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove non-alphanumeric chars except spaces\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    # Trim leading/trailing spaces\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def calculate_rouge_scores(predicted_text, reference_boxes):\n",
    "    \"\"\"Calculate ROUGE scores between prediction and references\"\"\"\n",
    "    # Initialize the ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Combine all reference texts\n",
    "    all_text = ' '.join([box['text'] for box in reference_boxes])\n",
    "    normalized_reference = normalize_text(all_text)\n",
    "    \n",
    "    # Normalize predicted text\n",
    "    normalized_prediction = normalize_text(predicted_text)\n",
    "    \n",
    "    # Calculate scores\n",
    "    scores = scorer.score(normalized_reference, normalized_prediction)\n",
    "    \n",
    "    # Calculate per-label scores\n",
    "    per_label_scores = {}\n",
    "    for label_type in set(box['label'] for box in reference_boxes):\n",
    "        # Get text for this label type\n",
    "        label_text = ' '.join([box['text'] for box in reference_boxes if box['label'] == label_type])\n",
    "        normalized_label_text = normalize_text(label_text)\n",
    "        \n",
    "        # Calculate scores for this label\n",
    "        label_scores = scorer.score(normalized_label_text, normalized_prediction)\n",
    "        per_label_scores[label_type] = {\n",
    "            'rouge1': label_scores['rouge1'].fmeasure,\n",
    "            'rouge2': label_scores['rouge2'].fmeasure,\n",
    "            'rougeL': label_scores['rougeL'].fmeasure\n",
    "        }\n",
    "    \n",
    "    # Debug info\n",
    "    debug_info = {\n",
    "        'reference_sample': normalized_reference[:100] + \"...\" if len(normalized_reference) > 100 else normalized_reference,\n",
    "        'prediction_sample': normalized_prediction[:100] + \"...\" if len(normalized_prediction) > 100 else normalized_prediction,\n",
    "        'reference_length': len(normalized_reference),\n",
    "        'prediction_length': len(normalized_prediction)\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'rouge1': scores['rouge1'].fmeasure,\n",
    "        'rouge2': scores['rouge2'].fmeasure,\n",
    "        'rougeL': scores['rougeL'].fmeasure,\n",
    "        'per_label': per_label_scores,\n",
    "        'debug': debug_info\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # Load annotations\n",
    "    annotations = parse_annotations(CFG.annotation_file)\n",
    "    print(f\"Loaded annotations for {len(annotations)} images\")\n",
    "    \n",
    "    # Build model\n",
    "    processor, model = build_model()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Process images - either all or just first 3\n",
    "    if CFG.process_all:\n",
    "        test_img_ids = list(annotations.keys())\n",
    "    else:\n",
    "        test_img_ids = list(annotations.keys())[:3]\n",
    "    \n",
    "    print(f\"Processing {len(test_img_ids)} images\")\n",
    "    \n",
    "    # Process each image\n",
    "    for img_id in test_img_ids:\n",
    "        annotation = annotations[img_id]\n",
    "        print(f\"\\nProcessing image {img_id}: {annotation['filename']}\")\n",
    "        \n",
    "        # Display annotation summary\n",
    "        print(f\"Annotations: {len(annotation['boxes'])} boxes\")\n",
    "        for i, box in enumerate(annotation['boxes']):\n",
    "            if i < 3 or i == len(annotation['boxes']) - 1:  # Show first 3 and last annotation\n",
    "                print(f\"  {box['label']}: {box['text']}\")\n",
    "            elif i == 3:\n",
    "                print(f\"  ... ({len(annotation['boxes']) - 4} more) ...\")\n",
    "        \n",
    "        # Load image\n",
    "        img_path = os.path.join(CFG.image_root, annotation['filename'])\n",
    "        \n",
    "        try:\n",
    "            # Try loading with PIL directly first\n",
    "            pil_image = Image.open(img_path)\n",
    "        except:\n",
    "            # Fallback to OpenCV\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                print(f\"Image {img_path} not found. Skipping.\")\n",
    "                continue\n",
    "                \n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            pil_image = Image.fromarray(image_rgb)\n",
    "        \n",
    "        # Run OCR inference\n",
    "        print(\"Running OCR extraction...\")\n",
    "        ocr_result = inference(image=pil_image, model=model, processor=processor)\n",
    "        \n",
    "        # Print OCR result preview\n",
    "        print(\"\\nOCR Result Preview:\")\n",
    "        preview = ocr_result['result'][:150] + \"...\" if len(ocr_result['result']) > 150 else ocr_result['result']\n",
    "        print(preview)\n",
    "        \n",
    "        # Calculate ROUGE scores\n",
    "        print(\"\\nCalculating ROUGE scores...\")\n",
    "        rouge_scores = calculate_rouge_scores(ocr_result['result'], annotation['boxes'])\n",
    "        \n",
    "        print(f\"ROUGE-1: {rouge_scores['rouge1']:.4f}\")\n",
    "        print(f\"ROUGE-2: {rouge_scores['rouge2']:.4f}\")\n",
    "        print(f\"ROUGE-L: {rouge_scores['rougeL']:.4f}\")\n",
    "        \n",
    "        # Print per-label scores\n",
    "        print(\"\\nPer-label ROUGE-1 scores:\")\n",
    "        for label, scores in rouge_scores['per_label'].items():\n",
    "            print(f\"  {label}: {scores['rouge1']:.4f}\")\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'image_id': img_id,\n",
    "            'filename': annotation['filename'],\n",
    "            'ocr_result': ocr_result['result'],\n",
    "            'ground_truth': [box['text'] for box in annotation['boxes']],\n",
    "            'rouge_scores': rouge_scores,\n",
    "            'inference_time': ocr_result['inference_time']\n",
    "        })\n",
    "        \n",
    "        # Save intermediate results\n",
    "        with open(CFG.output_path, 'w') as f:\n",
    "            json.dump({\n",
    "                'model': CFG.model_name,\n",
    "                'results': results\n",
    "            }, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nEvaluation complete. Results saved to {CFG.output_path}\")\n",
    "    \n",
    "    # Calculate average scores\n",
    "    if results:\n",
    "        avg_rouge1 = sum(r['rouge_scores']['rouge1'] for r in results) / len(results)\n",
    "        avg_rouge2 = sum(r['rouge_scores']['rouge2'] for r in results) / len(results)\n",
    "        avg_rougeL = sum(r['rouge_scores']['rougeL'] for r in results) / len(results)\n",
    "        avg_time = sum(r['inference_time'] for r in results) / len(results)\n",
    "        \n",
    "        print(\"\\nAverage ROUGE Scores:\")\n",
    "        print(f\"  ROUGE-1: {avg_rouge1:.4f}\")\n",
    "        print(f\"  ROUGE-2: {avg_rouge2:.4f}\")\n",
    "        print(f\"  ROUGE-L: {avg_rougeL:.4f}\")\n",
    "        print(f\"Average inference time: {avg_time:.2f} seconds\")\n",
    "        \n",
    "        # Per-label average scores\n",
    "        print(\"\\nAverage ROUGE-1 per label:\")\n",
    "        label_types = set()\n",
    "        for r in results:\n",
    "            label_types.update(r['rouge_scores']['per_label'].keys())\n",
    "        \n",
    "        label_avg_scores = {}\n",
    "        for label in label_types:\n",
    "            scores = [r['rouge_scores']['per_label'][label]['rouge1'] \n",
    "                     for r in results \n",
    "                     if label in r['rouge_scores']['per_label']]\n",
    "            if scores:\n",
    "                avg_score = sum(scores) / len(scores)\n",
    "                print(f\"  {label}: {avg_score:.4f} (from {len(scores)} images)\")\n",
    "                label_avg_scores[label] = avg_score\n",
    "        \n",
    "        # Save summary\n",
    "        with open(\"qwen2_vl_summary.json\", 'w') as f:\n",
    "            json.dump({\n",
    "                'model': CFG.model_name,\n",
    "                'num_images_processed': len(results),\n",
    "                'avg_rouge1': avg_rouge1,\n",
    "                'avg_rouge2': avg_rouge2,\n",
    "                'avg_rougeL': avg_rougeL,\n",
    "                'avg_inference_time': avg_time,\n",
    "                'per_label_avg_scores': label_avg_scores\n",
    "            }, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nSummary saved to qwen2_vl_summary.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOTH HANDWRITTEN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T00:57:24.982187Z",
     "iopub.status.busy": "2025-05-21T00:57:24.981851Z",
     "iopub.status.idle": "2025-05-21T01:01:28.282257Z",
     "shell.execute_reply": "2025-05-21T01:01:28.281542Z",
     "shell.execute_reply.started": "2025-05-21T00:57:24.982158Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 00:57:44.961879: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747789065.398135      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747789065.513354      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: /kaggle/input/qwen2-vl/transformers/7b-instruct/1\n",
      "Loaded test image: /kaggle/input/ocr-receipts-text-detection/images/1.jpg, size: (688, 1024)\n",
      "Baseline GPU Memory: 0.00 MB allocated, 0.00 MB reserved\n",
      "After loading processor: 0.00 MB allocated, 0.00 MB reserved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8baef5611aca4e6583f4ef2fd255eed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After loading model: 7218.16 MB allocated, 7222.00 MB reserved\n",
      "Model size in memory: 7218.16 MB\n",
      "\n",
      "Run 1/3\n",
      "Memory for input processing: 16.61 MB\n",
      "Memory for generation: 8.14 MB\n",
      "Total memory increase: 24.75 MB\n",
      "Peak memory: 7546.70 MB\n",
      "Inference time: 36.23 seconds\n",
      "\n",
      "Run 2/3\n",
      "Memory for input processing: 0.00 MB\n",
      "Memory for generation: 0.00 MB\n",
      "Total memory increase: 0.00 MB\n",
      "Peak memory: 7546.71 MB\n",
      "Inference time: 33.35 seconds\n",
      "\n",
      "Run 3/3\n",
      "Memory for input processing: 0.00 MB\n",
      "Memory for generation: 0.00 MB\n",
      "Total memory increase: 0.00 MB\n",
      "Peak memory: 7546.71 MB\n",
      "Inference time: 33.36 seconds\n",
      "\n",
      "Average across runs:\n",
      "Input processing memory: 5.54 MB\n",
      "Generation memory: 2.71 MB\n",
      "Total memory increase: 8.25 MB\n",
      "Peak memory: 7546.71 MB\n",
      "Inference time: 34.31 seconds\n",
      "Results saved to memory_analysis_results.json\n",
      "Memory usage plot saved to memory_usage.png\n",
      "Memory by stage plot saved to memory_by_stage.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAJOCAYAAACqS2TfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAB7X0lEQVR4nOzde3zP9f//8ft75w2b02ZkDhE2p5hiyCGHYUQ55zDnaAiRfOrj9CmkEh1QYZNDopBDaI6FhablLJWsMOdtjttsr98ffnt/vW14T162cbteLrvU+/l6vl6vx+vt/dqe9/frZDEMwxAAAAAAALjvHLK7AAAAAAAAHlaEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAACAHCAiIkIWi0U///xzdpcCALiPCN0A8JCYPn26LBaLatasmd2l5EhpaWn64osv1KRJExUuXFjOzs7y8fFR06ZN9dlnnykpKcmmv8Visf44ODioWLFiatq0qTZv3pyh38CBAzNd59dffy2LxZJhnlulhy2LxaKtW7dmmG4Yhvz8/GSxWNSyZcssbffDYuzYsbJYLDp79mym0ytVqqQGDRo82KJysZUrV6p+/fry8fGRh4eHHn/8cXXo0EFr16619jlx4oTGjh2rmJiY7CsUAB4ChG4AeEgsWLBApUqV0s6dO/X7779ndzk5ytWrV9WiRQuFhobqypUrGj58uD777DONHDlSbm5uevnll/Xyyy9nmK9JkyaaN2+e5s6dq/79+2vPnj169tlntWbNGlPqdHNz08KFCzO0b9myRf/8849cXV1NWS8eLe+9956ee+45WSwWjRo1Sh988IHatm2rI0eOaNGiRdZ+J06c0Lhx4wjdAPAvOWV3AQCAf+/o0aPavn27li5dqpdeekkLFizQmDFjHmgNaWlpSk5Olpub2wNdrz2GDh2qdevWaerUqXrllVdspr366qs6cuSIIiMjM8xXrlw5de3a1fr6+eefV5UqVTR16lQ1b978vtfZokULLVmyRB9++KGcnP7vT/TChQsVGBh426O8Od3ly5eVJ0+e7C4Dkq5fv67//e9/atKkib7//vsM00+fPp0NVQHAw40j3QDwEFiwYIEKFCigkJAQtWvXTgsWLLBOS0lJUcGCBdWzZ88M8yUmJsrNzU3Dhw+3tiUlJWnMmDEqW7asXF1d5efnp9deey3T068HDhyoBQsWqGLFinJ1dbWemvree++pdu3aKlSokNzd3RUYGKivv/46w/qvXr2qwYMHq3DhwsqXL5+ee+45HT9+XBaLRWPHjrXpe/z4cfXq1UtFihSRq6urKlasqDlz5tz1vfn77781a9YsNWvWLEPgTvfEE09keqT7VpUrV1bhwoV19OjRu/a9F507d9a5c+dsvgBITk7W119/rRdffDHTedLS0jR16lRVrFhRbm5uKlKkiF566SVduHDBpl+pUqXUsmVLbd68WTVq1JC7u7sqV65sPfV96dKlqly5stzc3BQYGKhffvklw7o2btyoZ555Rnny5FH+/PnVunVrHTx40KZP+mngBw4c0IsvvqgCBQqobt26Cg8Pl8ViyXS5EyZMkKOjo44fP57Vt+yOPvroI1WsWFEeHh4qUKCAatSoYXMmwbFjx/Tyyy+rfPnycnd3V6FChdS+fXv99ddfGZa1Z88e1a9fX+7u7ipevLjeeust6zbd2n/NmjXW9ylfvnwKCQnR/v377a77ypUreumll1SoUCF5enqqe/fuNv+eoaGhKly4sFJSUjLM27RpU5UvX/62yz579qwSExNVp06dTKf7+PhIkjZv3qynnnpKktSzZ0/r5Q8RERGSpB9//FHt27dXiRIlrL8nhg4dqqtXr2ZY5pIlSxQQECA3NzdVqlRJy5YtU48ePVSqVCmbfvZ+lgEgtyF0A8BDYMGCBXrhhRfk4uKizp0768iRI9q1a5ckydnZWc8//7yWL1+u5ORkm/mWL1+upKQkderUSdKNQe9zzz2n9957T61atdJHH32kNm3a6IMPPlDHjh0zrHfjxo0aOnSoOnbsqGnTplkH0dOmTVO1atU0fvx4TZgwQU5OTmrfvr1Wr15tM3+PHj300UcfqUWLFnrnnXfk7u6ukJCQDOs5deqUatWqpfXr12vgwIGaNm2aypYtq969e2vq1Kl3fG/WrFmj1NRUmyPW9+rChQu6cOGCChUq9K+XlZlSpUopKChIX375pbVtzZo1SkhIsP4b3eqll17SiBEjVKdOHU2bNk09e/bUggULFBwcnCGU/f7773rxxRfVqlUrTZw4URcuXFCrVq20YMECDR06VF27dtW4ceP0xx9/qEOHDkpLS7POu379egUHB+v06dMaO3ashg0bpu3bt6tOnTqZhtT27dvrypUrmjBhgvr27at27drJ3d3d5guhdAsWLFCDBg302GOP3eM7l9Hnn3+uwYMHKyAgQFOnTtW4ceP05JNPaseOHdY+u3bt0vbt29WpUyd9+OGH6t+/vzZs2KAGDRroypUr1n7Hjx9Xw4YNtX//fo0aNUpDhw7VggULNG3atAzrnTdvnkJCQpQ3b1698847+u9//6sDBw6obt26mb5PmRk4cKAOHjyosWPHqnv37lqwYIHatGkjwzAkSd26ddO5c+e0bt06m/ni4uK0cePGO37WfXx85O7urpUrV+r8+fO37efv76/x48dLkvr166d58+Zp3rx5qlevnqQbQfrKlSsaMGCAPvroIwUHB+ujjz5S9+7dbZazevVqdezYUc7Ozpo4caJeeOEF9e7dW9HR0RnWmZXPMgDkKgYAIFf7+eefDUlGZGSkYRiGkZaWZhQvXtx45ZVXrH3WrVtnSDJWrlxpM2+LFi2Mxx9/3Pp63rx5hoODg/Hjjz/a9Js5c6Yhydi2bZu1TZLh4OBg7N+/P0NNV65csXmdnJxsVKpUyXj22WetbdHR0YYkY8iQITZ9e/ToYUgyxowZY23r3bu3UbRoUePs2bM2fTt16mR4eXllWN/Nhg4dakgyYmJibNqTkpKMM2fOWH9uXbYko3fv3saZM2eM06dPGzt27DAaNWpkSDLef/99m35hYWGZrnvJkiWGJGPTpk23rc8wDCM8PNyQZOzatcv4+OOPjXz58lm3qX379kbDhg0NwzCMkiVLGiEhIdb5fvzxR0OSsWDBApvlrV27NkN7yZIlDUnG9u3brW3pnwt3d3fj2LFj1vZPP/00Q91PPvmk4ePjY5w7d87a9uuvvxoODg5G9+7drW1jxowxJBmdO3fOsJ2dO3c2ihUrZqSmplrbdu/ebUgywsPD7/gepS/3zJkzmU6vWLGiUb9+fevr1q1bGxUrVrzjMjP73ERFRRmSjC+++MLaNmjQIMNisRi//PKLte3cuXNGwYIFDUnG0aNHDcMwjIsXLxr58+c3+vbta7PMuLg4w8vLK0P7rdI/B4GBgUZycrK1ffLkyYYk49tvvzUMwzBSU1ON4sWLGx07drSZf8qUKYbFYjH+/PPPO65n9OjRhiQjT548RvPmzY23337biI6OztBv165dt/23yey9mzhxomGxWGw+S5UrVzaKFy9uXLx40dq2efNmQ5JRsmRJa1tWPssAkNtwpBsAcrkFCxaoSJEiatiwoaQbp3137NhRixYtUmpqqiTp2WefVeHChfXVV19Z57tw4YIiIyNtjmAvWbJE/v7+qlChgs6ePWv9efbZZyVJmzZtsll3/fr1FRAQkKEmd3d3m/UkJCTomWee0e7du63t6aei33pa96BBg2xeG4ahb775Rq1atZJhGDZ1BQcHKyEhwWa5t0pMTJQk5c2b16b9u+++k7e3t/WnZMmSGeadPXu2vL295ePjo5o1a2rbtm0aNmyYhgwZctv1/VsdOnTQ1atXtWrVKl28eFGrVq267anlS5YskZeXl5o0aWLzvgQGBipv3rwZ/r0CAgIUFBRkfZ1+p/tnn31WJUqUyND+559/SpJOnjypmJgY9ejRQwULFrT2q1Klipo0aaLvvvsuQ239+/fP0Na9e3edOHHCpq4FCxbI3d1dbdu2vet7kxX58+fXP//8Yz3jIzM3f05TUlJ07tw5lS1bVvnz58/wWQ0KCtKTTz5pbStYsKC6dOlis7zIyEjFx8erc+fONv8ejo6OqlmzZoZ/j9vp16+fnJ2dra8HDBggJycn6/vs4OCgLl26aMWKFbp48aK134IFC1S7dm2VLl36jssfN26cFi5cqGrVqmndunV64403FBgYqOrVq2e4XOB2bn7vLl++rLNnz6p27doyDMN6CcGJEye0d+9ede/e3Wb/q1+/vipXrmyzvKx+lgEgNyF0A0AulpqaqkWLFqlhw4Y6evSofv/9d/3++++qWbOmTp06pQ0bNkiSnJyc1LZtW3377bfWa7OXLl2qlJQUm9B95MgR7d+/3yaMent7q1y5cpIy3mTpdoP7VatWqVatWnJzc1PBggXl7e2tGTNmKCEhwdrn2LFjcnBwyLCMsmXL2rw+c+aM4uPj9dlnn2WoK/069Tvd/ClfvnySpEuXLtm016lTR5GRkYqMjFTTpk0znbd169aKjIzU+vXrtWPHDp09e1bvv/++HByy9ufTYrHY3dfb21uNGzfWwoULtXTpUqWmpqpdu3aZ9j1y5IgSEhLk4+OT4b25dOlShvfl5mAtSV5eXpIkPz+/TNvTr6U9duyYJGV6rbC/v7/Onj2ry5cv27Rn9tlo0qSJihYtaj3FPC0tTV9++aVat25t/Xf6N25+n0eOHKm8efPq6aef1hNPPKGwsDBt27bNpv/Vq1c1evRo+fn5ydXVVYULF5a3t7fi4+MzfFZv/VxKGT+rR44ckXTjS4xb/z2+//57u29S9sQTT9i8zps3r4oWLWpzenr37t119epVLVu2TJJ0+PBhRUdHq1u3bnato3Pnzvrxxx914cIFff/993rxxRf1yy+/qFWrVrp27dpd54+NjbV+CZM3b155e3urfv36kmR979I/N/a+d1n5LANAbsLdywEgF9u4caNOnjypRYsW2TzqJ92CBQusgbJTp0769NNPtWbNGrVp00aLFy9WhQoVVLVqVWv/tLQ0Va5cWVOmTMl0fbeGs5uPdqX78ccf9dxzz6levXqaPn26ihYtKmdnZ4WHh2f6OKy7Sb+uuGvXrgoNDc20T5UqVW47f4UKFSRJ+/bts9nW9HArSfPnz8903uLFi1v73I6rq2umN4+SZL0uOKt3dH/xxRfVt29fxcXFqXnz5sqfP3+m/dLS0uTj45PpddLSjW28maOjY6b9btdu/P9riO9FZp8NR0dHvfjii/r88881ffp0bdu2TSdOnLDrevv09/BO7/XN77O/v78OHz6sVatWae3atfrmm280ffp0jR49WuPGjZN046yK8PBwDRkyREFBQfLy8pLFYlGnTp1srme3V/o88+bNk6+vb4bpN9+R/t8KCAhQYGCg5s+fr+7du2v+/PlycXFRhw4dsrQcT09PNWnSRE2aNJGzs7Pmzp2rHTt2WAN0ZlJTU9WkSROdP39eI0eOVIUKFZQnTx4dP35cPXr0uOf3LiufZQDITQjdAJCLLViwQD4+Pvrkk08yTFu6dKmWLVummTNnyt3dXfXq1VPRokX11VdfqW7dutq4caPeeOMNm3nKlCmjX3/9VY0aNcrS0dmbffPNN3Jzc9O6detsnisdHh5u069kyZJKS0vT0aNHbY7s3fqMcW9vb+XLl0+pqal3DcCZad68uRwdHbVgwYIMpwPfDyVLltThw4cznZbentmp63fy/PPP66WXXtJPP/1kc0nArcqUKaP169erTp06mYbc+yW9/sy289ChQypcuLDdjwTr3r273n//fa1cuVJr1qyRt7e3goODs1TDrV/+XLlyRX///XeGMxby5Mmjjh07qmPHjkpOTtYLL7ygt99+W6NGjZKbm5u+/vprhYaG6v3337fOc+3aNcXHx2dY962fSynjZ7VMmTKSbtys7F4+q+mOHDlivVxEunGWxsmTJ9WiRQubft27d9ewYcN08uRJLVy4UCEhISpQoMA9r7dGjRqaO3euTp48Ken2Z2js3btXv/32m+bOnWtz47RbH7uX/m9m73v3ID7LAJAdOL0cAHKpq1evaunSpWrZsqXatWuX4WfgwIG6ePGiVqxYIenGdaDt2rXTypUrNW/ePF2/fj3DHck7dOig48eP6/PPP890fbeeQpwZR0dHWSwW6/XkkvTXX39p+fLlNv3Sg9b06dNt2j/66KMMy2vbtq2++eYb7du3L8P6zpw5c8d6SpQooV69emnNmjX6+OOPM+3zb47otmjRQj/99FOGuzHHx8drwYIFevLJJzM96nknefPm1YwZMzR27Fi1atXqtv06dOig1NRU/e9//8sw7fr16xnC470qWrSonnzySc2dO9dmmfv27dP333+fIQzeSZUqVVSlShXNmjVL33zzjTp16mTXEeBGjRrJxcVFM2bMyHAk9bPPPtP169dtnp1+7tw5mz4uLi4KCAiQYRjWO2E7Ojpm+Lf/6KOPbD670o3PalRUlGJiYqxt58+fz3BUNjg4WJ6enpowYUKmd9u+22f15u25ef4ZM2Zk2D7pxiniFotFr7zyiv7880+7zhi4cuWKoqKiMp22Zs0aSf93GUH6Fym3fo7Sz4y4+b0zDCPD3dyLFSumSpUq6YsvvrC5vGPLli3au3evTd8H9VkGgOzAkW4AyKXSb6L03HPPZTq9Vq1a8vb21oIFC6zhumPHjvroo480ZswYVa5cWf7+/jbzdOvWTYsXL1b//v21adMm1alTR6mpqTp06JAWL16sdevWqUaNGnesKyQkRFOmTFGzZs304osv6vTp0/rkk09UtmxZ7dmzx9ovMDBQbdu21dSpU3Xu3DnVqlVLW7Zs0W+//SbJ9ijbpEmTtGnTJtWsWVN9+/ZVQECAzp8/r927d2v9+vV3fPSRJE2dOlVHjx7VoEGDtGjRIrVq1Uo+Pj46e/astm3bppUrV97x2cZ38vrrr2vJkiWqV6+eXnrpJVWoUEEnTpxQRESETp48meEIv71udyr9zerXr6+XXnpJEydOVExMjJo2bSpnZ2cdOXJES5Ys0bRp0257PXhWvfvuu2revLmCgoLUu3dvXb16VR999JG8vLwyPFP9brp37259Nry9j3Lz8fHR6NGj9eabb6pevXp67rnn5OHhoe3bt+vLL79U06ZNbb6gaNq0qXx9fVWnTh0VKVJEBw8e1Mcff6yQkBDr9eMtW7bUvHnz5OXlpYCAAEVFRWn9+vUZHgn32muvaf78+WrSpIkGDRqkPHnyaNasWSpRooTOnz9v/ax6enpqxowZ6tatm6pXr65OnTrJ29tbsbGxWr16terUqXPbL35ulpycrEaNGqlDhw46fPiwpk+frrp162bY1729vdWsWTMtWbJE+fPnz/Rxe7e6cuWKateurVq1aqlZs2by8/NTfHy8li9frh9//FFt2rRRtWrVJN04+pw/f37NnDlT+fLlU548eVSzZk1VqFBBZcqU0fDhw3X8+HF5enrqm2++yfR52hMmTFDr1q1Vp04d9ezZUxcuXNDHH3+sSpUq2QTxB/lZBoAHLtvumw4A+FdatWpluLm5GZcvX75tnx49ehjOzs7Wx2GlpaUZfn5+hiTjrbfeynSe5ORk45133jEqVqxouLq6GgUKFDACAwONcePGGQkJCdZ+usOjsmbPnm088cQThqurq1GhQgUjPDzc+sinm12+fNkICwszChYsaOTNm9do06aNcfjwYUOSMWnSJJu+p06dMsLCwgw/Pz/D2dnZ8PX1NRo1amR89tlndr1f169fN8LDw41nn33WKFiwoOHk5GQULlzYaNSokTFz5kzj6tWrNv3vtH23+ueff4w+ffoYjz32mOHk5GQULFjQaNmypfHTTz/ZNf/Njwy7k1sfGZbus88+MwIDAw13d3cjX758RuXKlY3XXnvNOHHixF3nzWw7jx49akgy3n33XZv29evXG3Xq1DHc3d0NT09Po1WrVsaBAwds+tzt0V6GYRgnT540HB0djXLlyt1xezMzf/58o1atWkaePHmsn69x48YZ165ds+n36aefGvXq1TMKFSpkuLq6GmXKlDFGjBhh8xm+cOGC0bNnT6Nw4cJG3rx5jeDgYOPQoUNGyZIljdDQUJvl/fLLL8YzzzxjuLq6GsWLFzcmTpxofPjhh4YkIy4uzqbvpk2bjODgYMPLy8twc3MzypQpY/To0cP4+eef77ht6Z+DLVu2GP369TMKFChg5M2b1+jSpYvNo9putnjxYkOS0a9fP7vev5SUFOPzzz832rRpY5QsWdJwdXU1PDw8jGrVqhnvvvuukZSUZNP/22+/NQICAgwnJyebx4cdOHDAaNy4sZE3b16jcOHCRt++fY1ff/0100eMLVq0yKhQoYLh6upqVKpUyVixYoXRtm1bo0KFChnqs+ezDAC5jcUw/sU5dQAA3GcxMTGqVq2a5s+fb8o12Mh+Z8+eVdGiRTV69Gj997//ze5y7tmQIUP06aef6tKlS7e9GZ3Zvv32W7Vp00Y//PCDnnnmmWyp4V48+eST8vb2znAdOAA8jLimGwCQbTK7E/XUqVPl4OCgevXqZUNFeBAiIiKUmppq9+OtcoJbP6vnzp3TvHnzVLdu3WwL3JL0+eef6/HHH1fdunWzrYY7SUlJ0fXr123aNm/erF9//VUNGjTInqIA4AHjmm4AQLaZPHmyoqOj1bBhQzk5OWnNmjVas2aN+vXrl+EO1cj9Nm7cqAMHDujtt99WmzZtVKpUqewuyW5BQUFq0KCB/P39derUKc2ePVuJiYnZdqR+0aJF2rNnj1avXq1p06bd89MGzHb8+HE1btxYXbt2VbFixXTo0CHNnDlTvr6+6t+/f3aXBwAPBKeXAwCyTWRkpMaNG6cDBw7o0qVLKlGihLp166Y33njjvj7TGDlDgwYNtH37dtWpU0fz58/XY489lt0l2e0///mPvv76a/3zzz+yWCyqXr26xowZ868eDfZvWCwW5c2bVx07dtTMmTNz7P6SkJCgfv36adu2bTpz5ozy5MmjRo0aadKkSdZHrAHAw47QDQAAAACASbimGwAAAAAAkxC6AQAAAAAwSc68ACiHSUtL04kTJ5QvX74ce6MSAAAAAMCDYxiGLl68qGLFisnB4fbHswnddjhx4gR30QUAAAAAZPD333+rePHit51O6LZDvnz5JN14Mz09PbO5GgAAAABAdktMTJSfn581L94OodsO6aeUe3p6EroBAAAAAFZ3uwSZG6kBAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAIAcq1SpUrJYLBl+wsLCrH0aNGiQYXr//v0zXd65c+dUvHhxWSwWxcfH20xLSkrSG2+8oZIlS8rV1VWlSpXSnDlzbltbREREprVZLBadPn1aknTy5Em9+OKLKleunBwcHDRkyJC7bvNff/0li8UiR0dHHT9+3GbayZMn5eTkJIvFor/++sumf/qPi4uLypYtq7feekuGYdx1fTCXU3YXAAAAAAC3s2vXLqWmplpf79u3T02aNFH79u1t+vXt21fjx4+3vvbw8Mh0eb1791aVKlUyhFlJ6tChg06dOqXZs2erbNmyOnnypNLS0m5bW8eOHdWsWTObth49eujatWvy8fGRdCPIe3t7680339QHH3xw9w2+yWOPPaYvvvhCo0aNsrbNnTtXjz32mGJjYzP0X79+vSpWrKikpCRt3bpVffr0UdGiRdW7d+8srRf3F0e6AQAAAORY3t7e8vX1tf6sWrVKZcqUUf369W36eXh42PTz9PTMsKwZM2YoPj5ew4cPzzBt7dq12rJli7777js1btxYpUqVUlBQkOrUqXPb2tzd3W3W6ejoqI0bN9qE3FKlSmnatGnq3r27vLy8srTtoaGhCg8Pt2kLDw9XaGhopv0LFSokX19flSxZUl26dFGdOnW0e/fuLK0T9x+hGwAAAECukJycrPnz56tXr16yWCw20xYsWKDChQurUqVKGjVqlK5cuWIz/cCBAxo/fry++OILOThkjEErVqxQjRo1NHnyZD322GMqV66chg8frqtXr9pd3xdffCEPDw+1a9fu3jbwFs8995wuXLigrVu3SpK2bt2qCxcuqFWrVned9+eff1Z0dLRq1qx5X2rBveP0cgAAAAC5wvLlyxUfH68ePXrYtL/44osqWbKkihUrpj179mjkyJE6fPiwli5dKunGKd6dO3fWu+++qxIlSujPP//MsOw///xTW7dulZubm5YtW6azZ8/q5Zdf1rlz5zIcbb6d2bNn68UXX5S7u/u/3lZJcnZ2VteuXTVnzhzVrVtXc+bMUdeuXeXs7Jxp/9q1a8vBwUHJyclKSUlRv3791L179/tSC+4doRsAAABArjB79mw1b95cxYoVs2nv16+f9f8rV66sokWLqlGjRvrjjz9UpkwZjRo1Sv7+/uratettl52WliaLxaIFCxZYTwOfMmWK2rVrp+nTp981SEdFRengwYOaN2/ev9jCjHr16qXatWtrwoQJWrJkiaKionT9+vVM+3711Vfy9/dXSkqK9u3bp0GDBqlAgQKaNGnSfa0JWcPp5QAAAAByvGPHjmn9+vXq06fPXfumn1L9+++/S5I2btyoJUuWyMnJSU5OTmrUqJEkqXDhwhozZowkqWjRonrsscdsrrv29/eXYRj6559/7rrOWbNm6cknn1RgYGCWt+1OKleurAoVKqhz587y9/dXpUqVbtvXz89PZcuWlb+/v9q3b68hQ4bo/fff17Vr1+5rTcgajnQDAAAAyPHCw8Pl4+OjkJCQu/aNiYmRdCNIS9I333xjc232rl271KtXL/34448qU6aMJKlOnTpasmSJLl26pLx580qSfvvtNzk4OKh48eJ3XN+lS5e0ePFiTZw48V427a569eqll19+WTNmzMjSfI6Ojrp+/bqSk5Pl5uZmSm24O0I3AAAAgBwtLS3NetduJyfbCPPHH39o4cKFatGihQoVKqQ9e/Zo6NChqlevnqpUqSJJ1mCd7uzZs5JuHMnOnz+/pBvXhf/vf/9Tz549NW7cOJ09e1YjRoxQr169rKeWL1u2TKNGjdKhQ4dslvfVV1/p+vXrtz19Pf1LgEuXLunMmTOKiYmRi4uLAgIC7Nr+vn37qn379tZab+fcuXOKi4vT9evXtXfvXk2bNk0NGzbM9E7ueHAI3QAAAABytPXr1ys2Nla9evXKMM3FxUXr16/X1KlTdfnyZfn5+alt27Z68803s7SOvHnzKjIyUoMGDVKNGjVUqFAhdejQQW+99Za1T0JCgg4fPpxh3tmzZ+uFF164bSiuVq2a9f+jo6O1cOFClSxZUn/99ZddtTk5Oalw4cJ37de4cWNJN45wFy1aVC1atNDbb79t1zpgHothGEZ2F5HTJSYmysvLSwkJCXxLBAAAAACwOydyIzUAAAAAAExC6AYAAAAAwCRc0w0AAAA8CizZXQCQRQ/JhdAc6QYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoRo5QqlQpWSyWDD9hYWGSpPPnz2vQoEEqX7683N3dVaJECQ0ePFgJCQk2yxk8eLACAwPl6uqqJ598MtN1rVu3TrVq1VK+fPnk7e2ttm3b6q+//rpjfW+//bZq164tDw8P5c+f/7b9IiIiVKVKFbm5ucnHx8da/922e9GiRRmmVaxYURaLRRERERn6WywWOTo6qlixYurdu7cuXLhwx/UAAAAAyB6EbuQIu3bt0smTJ60/kZGRkqT27dtLkk6cOKETJ07ovffe0759+xQREaG1a9eqd+/eGZbVq1cvdezYMdP1HD16VK1bt9azzz6rmJgYrVu3TmfPntULL7xwx/qSk5PVvn17DRgw4LZ9pkyZojfeeEOvv/669u/fr/Xr1ys4OPiu2+7n56fw8HCbtp9++klxcXHKkydPhv7jx4/XyZMnFRsbqwULFuiHH37Q4MGD77oeAAAAAA+eU3YXAEiSt7e3zetJkyapTJkyql+/viSpUqVK+uabb6zTy5Qpo7fffltdu3bV9evX5eR046P84YcfSpLOnDmjPXv2ZFhPdHS0UlNT9dZbb8nB4cZ3TsOHD1fr1q2VkpIiZ2fnTOsbN26cJNkcdb7ZhQsX9Oabb2rlypVq1KiRtb1KlSp33fYuXbrogw8+0N9//y0/Pz9J0pw5c9SlSxd98cUXGfrny5dPvr6+kqTHHntMoaGh+vLLL++6HgAAAAAPHke6keMkJydr/vz56tWrlywWy237JSQkyNPT0xq47REYGCgHBweFh4crNTVVCQkJmjdvnho3bnzbwG2PyMhIpaWl6fjx4/L391fx4sXVoUMH/f3333edt0iRIgoODtbcuXMlSVeuXNFXX32lXr163XXe48ePa+XKlapZs+Y91w4AAADAPIRu5DjLly9XfHy8evTocds+Z8+e1f/+9z/169cvS8suXbq0vv/+e/3nP/+Rq6ur8ufPr3/++UeLFy/+VzX/+eefSktL04QJEzR16lR9/fXXOn/+vJo0aaLk5OS7zt+rVy9FRETIMAx9/fXXKlOmzG2vSR85cqTy5s0rd3d3FS9eXBaLRVOmTPlX9QMAAAAwB6EbOc7s2bPVvHlzFStWLNPpiYmJCgkJUUBAgMaOHZulZcfFxalv374KDQ3Vrl27tGXLFrm4uKhdu3YyDOOea05LS1NKSoo+/PBDBQcHq1atWvryyy915MgRbdq06a7zh4SE6NKlS/rhhx80Z86cOx7lHjFihGJiYrRnzx5t2LDBOn9qauo91w8AAADAHFzTjRzl2LFjWr9+vZYuXZrp9IsXL6pZs2bKly+fli1bluVTwj/55BN5eXlp8uTJ1rb58+fLz89PO3bsUK1ate6p7qJFi0qSAgICrG3e3t4qXLiwYmNj7zq/k5OTunXrpjFjxmjHjh1atmzZbfsWLlxYZcuWlSQ98cQTmjp1qoKCgrRp0yY1btz4nuoHAAAAYA6OdCNHCQ8Pl4+Pj0JCQjJMS0xMVNOmTeXi4qIVK1bIzc0ty8u/cuWK9QZq6RwdHSXdOFp9r+rUqSNJOnz4sLXt/PnzOnv2rEqWLGnXMnr16qUtW7aodevWKlCggN3rTq//6tWrWagYAAAAwINA6EaOkZaWpvDwcIWGhma4OVp64L58+bJmz56txMRExcXFKS4uzua06t9//10xMTGKi4vT1atXFRMTo5iYGOt11SEhIdq1a5fGjx+vI0eOaPfu3erZs6dKliypatWqSZJ27typChUq6Pjx49blxsbGKiYmRrGxsUpNTbUu99KlS5KkcuXKqXXr1nrllVe0fft27du3T6GhoapQoYIaNmxo1/b7+/vr7NmzGR4fdquLFy8qLi5OJ0+e1M6dOzVixAh5e3urdu3adq0HAAAAwIPD6eXIMdavX6/Y2NhMr2fevXu3duzYIUnWU6vTHT16VKVKlZIk9enTR1u2bLFOSw/S6X2effZZLVy4UJMnT9bkyZPl4eGhoKAgrV27Vu7u7pJuHA0/fPiwUlJSrMsZPXq09e7iNy9306ZNatCggSTpiy++0NChQxUSEiIHBwfVr19fa9euzdIp8IUKFbprn9GjR2v06NGSbpzC/tRTT+n777+3a14AAAAAD5bF+Dd3j3pEJCYmysvLy/qIKgAAACDXuf2TWIGcKYcnVXtzIqeXAwAAAABgEkI3AAAAAAAm4Zruh42F84aQy3CFCwAAAB5iHOkGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCTZGrpLlSoli8WS4ScsLEySdO3aNYWFhalQoULKmzev2rZtq1OnTtksIzY2ViEhIfLw8JCPj49GjBih69ev2/TZvHmzqlevLldXV5UtW1YREREPahMBAAAAAI+wbA3du3bt0smTJ60/kZGRkqT27dtLkoYOHaqVK1dqyZIl2rJli06cOKEXXnjBOn9qaqpCQkKUnJys7du3a+7cuYqIiNDo0aOtfY4ePaqQkBA1bNhQMTExGjJkiPr06aN169Y92I0FAAAAADxyLIZhGNldRLohQ4Zo1apVOnLkiBITE+Xt7a2FCxeqXbt2kqRDhw7J399fUVFRqlWrltasWaOWLVvqxIkTKlKkiCRp5syZGjlypM6cOSMXFxeNHDlSq1ev1r59+6zr6dSpk+Lj47V27Vq76kpMTJSXl5cSEhLk6el5/zf8frJYsrsCIGtyzq8gAAAebgwTkdvk8GGivTnR6QHWdEfJycmaP3++hg0bJovFoujoaKWkpKhx48bWPhUqVFCJEiWsoTsqKkqVK1e2Bm5JCg4O1oABA7R//35Vq1ZNUVFRNstI7zNkyJDb1pKUlKSkpCTr68TERElSWlqa0tLS7tMWm8SBy/SRy+T0fQoAgIcFw0TkNjl8mGhvNswxoXv58uWKj49Xjx49JElxcXFycXFR/vz5bfoVKVJEcXFx1j43B+706enT7tQnMTFRV69elbu7e4ZaJk6cqHHjxmVoP3PmjK5du3ZP2/fABAZmdwVA1pw+nd0VAADwaGCYiNwmhw8TL168aFe/HBO6Z8+erebNm6tYsWLZXYpGjRqlYcOGWV8nJibKz89P3t7eOf/08ujo7K4AyBofn+yuAACARwPDROQ2OXyY6ObmZle/HBG6jx07pvXr12vp0qXWNl9fXyUnJys+Pt7maPepU6fk6+tr7bNz506bZaXf3fzmPrfe8fzUqVPy9PTM9Ci3JLm6usrV1TVDu4ODgxxy+unbnKqL3Can71MAADwsGCYit8nhw0R7s2GO2Izw8HD5+PgoJCTE2hYYGChnZ2dt2LDB2nb48GHFxsYqKChIkhQUFKS9e/fq9E2np0ZGRsrT01MBAQHWPjcvI71P+jIAAAAAADBLtofutLQ0hYeHKzQ0VE5O/3fg3cvLS71799awYcO0adMmRUdHq2fPngoKClKtWrUkSU2bNlVAQIC6deumX3/9VevWrdObb76psLAw65Hq/v37688//9Rrr72mQ4cOafr06Vq8eLGGDh2aLdsLAAAAAHh0ZPvp5evXr1dsbKx69eqVYdoHH3wgBwcHtW3bVklJSQoODtb06dOt0x0dHbVq1SoNGDBAQUFBypMnj0JDQzV+/Hhrn9KlS2v16tUaOnSopk2bpuLFi2vWrFkKDg5+INsHAAAAAHh05ajndOdUPKcbMBG/ggAAeDAYJiK3yeHDRHtzYrafXg4AAAAAwMOK0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJgk20P38ePH1bVrVxUqVEju7u6qXLmyfv75Z+t0wzA0evRoFS1aVO7u7mrcuLGOHDlis4zz58+rS5cu8vT0VP78+dW7d29dunTJps+ePXv0zDPPyM3NTX5+fpo8efID2T4AAAAAwKMrW0P3hQsXVKdOHTk7O2vNmjU6cOCA3n//fRUoUMDaZ/Lkyfrwww81c+ZM7dixQ3ny5FFwcLCuXbtm7dOlSxft379fkZGRWrVqlX744Qf169fPOj0xMVFNmzZVyZIlFR0drXfffVdjx47VZ5999kC3FwAAAADwaLEYhmFk18pff/11bdu2TT/++GOm0w3DULFixfTqq69q+PDhkqSEhAQVKVJEERER6tSpkw4ePKiAgADt2rVLNWrUkCStXbtWLVq00D///KNixYppxowZeuONNxQXFycXFxfrupcvX65Dhw7dtc7ExER5eXkpISFBnp6e92nrTWKxZHcFQNZk368gAAAeLQwTkdvk8GGivTkxW490r1ixQjVq1FD79u3l4+OjatWq6fPPP7dOP3r0qOLi4tS4cWNrm5eXl2rWrKmoqChJUlRUlPLnz28N3JLUuHFjOTg4aMeOHdY+9erVswZuSQoODtbhw4d14cIFszcTAAAAAPCIcsrOlf/555+aMWOGhg0bpv/85z/atWuXBg8eLBcXF4WGhiouLk6SVKRIEZv5ihQpYp0WFxcnHx8fm+lOTk4qWLCgTZ/SpUtnWEb6tJtPZ5ekpKQkJSUlWV8nJiZKktLS0pSWlvZvN9tcDtl+mT6QNTl9nwIA4GHBMBG5TQ4fJtqbDbM1dKelpalGjRqaMGGCJKlatWrat2+fZs6cqdDQ0Gyra+LEiRo3blyG9jNnzthcS54jBQZmdwVA1pw+nd0VAADwaGCYiNwmhw8TL168aFe/bA3dRYsWVUBAgE2bv7+/vvnmG0mSr6+vJOnUqVMqWrSotc+pU6f05JNPWvucvmXQfv36dZ0/f946v6+vr06dOmXTJ/11ep+bjRo1SsOGDbO+TkxMlJ+fn7y9vXP+Nd3R0dldAZA1t5ypAgAATMIwEblNDh8murm52dUvW0N3nTp1dPjwYZu23377TSVLlpQklS5dWr6+vtqwYYM1ZCcmJmrHjh0aMGCAJCkoKEjx8fGKjo5W4P8/yrtx40alpaWpZs2a1j5vvPGGUlJS5OzsLEmKjIxU+fLlM5xaLkmurq5ydXXN0O7g4CCHnH76NqfqIrfJ6fsUAAAPC4aJyG1y+DDR3myYrZsxdOhQ/fTTT5owYYJ+//13LVy4UJ999pnCwsIkSRaLRUOGDNFbb72lFStWaO/everevbuKFSumNm3aSLpxZLxZs2bq27evdu7cqW3btmngwIHq1KmTihUrJkl68cUX5eLiot69e2v//v366quvNG3aNJuj2QAAAAAA3G/Z+sgwSVq1apVGjRqlI0eOqHTp0ho2bJj69u1rnW4YhsaMGaPPPvtM8fHxqlu3rqZPn65y5cpZ+5w/f14DBw7UypUr5eDgoLZt2+rDDz9U3rx5rX327NmjsLAw7dq1S4ULF9agQYM0cuRIu2rkkWGAiXhkGAAADwbDROQ2OXyYaG9OzPbQnRsQugET8SsIAIAHg2EicpscPkzMFc/pBgAAAADgYUboBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATJKtoXvs2LGyWCw2PxUqVLBOv3btmsLCwlSoUCHlzZtXbdu21alTp2yWERsbq5CQEHl4eMjHx0cjRozQ9evXbfps3rxZ1atXl6urq8qWLauIiIgHsXkAAAAAgEdcth/prlixok6ePGn92bp1q3Xa0KFDtXLlSi1ZskRbtmzRiRMn9MILL1inp6amKiQkRMnJydq+fbvmzp2riIgIjR492trn6NGjCgkJUcOGDRUTE6MhQ4aoT58+Wrdu3QPdTgAAAADAo8diGIaRXSsfO3asli9frpiYmAzTEhIS5O3trYULF6pdu3aSpEOHDsnf319RUVGqVauW1qxZo5YtW+rEiRMqUqSIJGnmzJkaOXKkzpw5IxcXF40cOVKrV6/Wvn37rMvu1KmT4uPjtXbtWrvqTExMlJeXlxISEuTp6fnvN9xMFkt2VwBkTfb9CgIA4NHCMBG5TQ4fJtqbE7P9SPeRI0dUrFgxPf744+rSpYtiY2MlSdHR0UpJSVHjxo2tfStUqKASJUooKipKkhQVFaXKlStbA7ckBQcHKzExUfv377f2uXkZ6X3SlwEAAAAAgFmcsnPlNWvWVEREhMqXL6+TJ09q3LhxeuaZZ7Rv3z7FxcXJxcVF+fPnt5mnSJEiiouLkyTFxcXZBO706enT7tQnMTFRV69elbu7e4a6kpKSlJSUZH2dmJgoSUpLS1NaWtq/22izOWT79yhA1uT0fQoAgIcFw0TkNjl8mGhvNszW0N28eXPr/1epUkU1a9ZUyZIltXjx4kzD8IMyceJEjRs3LkP7mTNndO3atWyoKAsCA7O7AiBrTp/O7goAAHg0MExEbpPDh4kXL160q1+2hu5b5c+fX+XKldPvv/+uJk2aKDk5WfHx8TZHu0+dOiVfX19Jkq+vr3bu3GmzjPS7m9/c59Y7np86dUqenp63DfajRo3SsGHDrK8TExPl5+cnb2/vnH9Nd3R0dlcAZI2PT3ZXAADAo4FhInKbHD5MdHNzs6tfjgrdly5d0h9//KFu3bopMDBQzs7O2rBhg9q2bStJOnz4sGJjYxUUFCRJCgoK0ttvv63Tp0/L5/8P3CMjI+Xp6amAgABrn++++85mPZGRkdZlZMbV1VWurq4Z2h0cHOSQ00/f5lRd5DY5fZ8CAOBhwTARuU0OHybamw2zdTOGDx+uLVu26K+//tL27dv1/PPPy9HRUZ07d5aXl5d69+6tYcOGadOmTYqOjlbPnj0VFBSkWrVqSZKaNm2qgIAAdevWTb/++qvWrVunN998U2FhYdbQ3L9/f/3555967bXXdOjQIU2fPl2LFy/W0KFDs3PTAQAAAACPgGw90v3PP/+oc+fOOnfunLy9vVW3bl399NNP8vb2liR98MEHcnBwUNu2bZWUlKTg4GBNnz7dOr+jo6NWrVqlAQMGKCgoSHny5FFoaKjGjx9v7VO6dGmtXr1aQ4cO1bRp01S8eHHNmjVLwcHBD3x7AQAAAACPlmx9TnduwXO6ARPxKwgAgAeDYSJymxw+TMw1z+kGAAAAAOBhRegGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATOJ0LzOlpKQoLi5OV65ckbe3twoWLHi/6wIAAAAAINez+0j3xYsXNWPGDNWvX1+enp4qVaqU/P395e3trZIlS6pv377atWuXmbUCAAAAAJCr2BW6p0yZolKlSik8PFyNGzfW8uXLFRMTo99++01RUVEaM2aMrl+/rqZNm6pZs2Y6cuSI2XUDAAAAAJDjWQzDMO7WqXPnznrzzTdVsWLFO/ZLSkpSeHi4XFxc1KtXr/tWZHZLTEyUl5eXEhIS5Onpmd3l3JnFkt0VAFlz919BAADgfmCYiNwmhw8T7c2JdoXuRx2hGzARv4IAAHgwGCYit8nhw0R7cyJ3LwcAAAAAwCRZCt2bNm3S+++/r23btkmSPv30U5UoUULe3t7q27evrl69akqRAAAAAADkRnY/Muzzzz/XgAEDVLp0ab3xxhsaM2aM3n77bXXr1k0ODg6aP3++ChUqpEmTJplZLwAAAAAAuYbd13RXqlRJL730kgYNGqS1a9eqVatWmjVrlkJDQyVJS5Ys0ahRo/T777+bWnB24JpuwERc0w0AwIPBMBG5TQ4fJt73a7r//PNPPffcc5KkZs2ayWKx6Omnn7ZOr1mzpv7+++9/UTIAAAAAAA8Xu0P3tWvX5O7ubn3t6uoqV1dXm9fXr1+/v9UBAAAAAJCL2X1Nt8Vi0cWLF+Xm5ibDMGSxWHTp0iUlJiZKkvW/AAAAAADgBrtDt2EYKleunM3ratWq2by2cD0xAAAAAABWdofuTZs2mVkHAAAAAAAPHbtDd/369c2sAwAAAACAh47dN1IDAAAAAABZY/eRbkdHR7v6paam3nMxAAAAAAA8TLJ0I7WSJUsqNDTU5gZqAAAAAAAgc3aH7p07d2r27NmaNm2aSpcurV69eqlLly4qUKCAmfUBAAAAAJBr2X1Nd40aNTRjxgydPHlSw4YN07Jly1S8eHF16tRJkZGRZtYIAAAAAECulOUbqbm5ualr167asGGD9u3bp9OnT6tZs2Y6f/68GfUBAAAAAJBr2X16+c3++ecfRUREKCIiQleuXNGIESPk6el5v2sDAAAAACBXszt0Jycna9myZZo9e7Z+/PFHNW/eXFOnTlXz5s3tvrM5AAAAAACPErtDd9GiRZUvXz6FhoZq+vTp8vHxkSRdvnzZph9HvAEAAAAAuMFiGIZhT0cHh/+7/NtisWSYbhiGLBbLQ/mc7sTERHl5eSkhISHnf6mQyb8NkKPZ9ysIAAD8WwwTkdvk8GGivTnR7iPdmzZtui+FAQAAAADwqLA7dNevX9/MOgAAAAAAeOjY9ciwW6/bvt/9AQAAAAB4GNkVusuWLatJkybp5MmTt+1jGIYiIyPVvHlzffjhh/etQAAAAAAAciu7Ti/fvHmz/vOf/2js2LGqWrWqatSooWLFisnNzU0XLlzQgQMHFBUVJScnJ40aNUovvfSS2XUDAAAAAJDj2X33ckmKjY3VkiVL9OOPP+rYsWO6evWqChcurGrVqik4OPihfWY3dy8HTMTdywEAeDAYJiK3yeHDRHtzYpZC96OK0A2YiF9BAAA8GAwTkdvk8GGivTnRrmu6AQAAAABA1hG6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJNkOXSXKlVK48ePV2xsrBn1AAAAAADw0Mhy6B4yZIiWLl2qxx9/XE2aNNGiRYuUlJT0rwuZNGmSLBaLhgwZYm27du2awsLCVKhQIeXNm1dt27bVqVOnbOaLjY1VSEiIPDw85OPjoxEjRuj69es2fTZv3qzq1avL1dVVZcuWVURExL+uFwAAAACAu7mn0B0TE6OdO3fK399fgwYNUtGiRTVw4EDt3r37norYtWuXPv30U1WpUsWmfejQoVq5cqWWLFmiLVu26MSJE3rhhRes01NTUxUSEqLk5GRt375dc+fOVUREhEaPHm3tc/ToUYWEhKhhw4aKiYnRkCFD1KdPH61bt+6eagUAAAAAwF4WwzD+1SPHU1JSNH36dI0cOVIpKSmqXLmyBg8erJ49e8pisdx1/kuXLql69eqaPn263nrrLT355JOaOnWqEhIS5O3trYULF6pdu3aSpEOHDsnf319RUVGqVauW1qxZo5YtW+rEiRMqUqSIJGnmzJkaOXKkzpw5IxcXF40cOVKrV6/Wvn37rOvs1KmT4uPjtXbtWru20d6HnucIdrznQI7y734FAQAAezFMRG6Tw4eJ9ubEe76RWkpKihYvXqznnntOr776qmrUqKFZs2apbdu2+s9//qMuXbrYtZywsDCFhISocePGNu3R0dFKSUmxaa9QoYJKlCihqKgoSVJUVJQqV65sDdySFBwcrMTERO3fv9/a59ZlBwcHW5cBAAAAAIBZnLI6w+7duxUeHq4vv/xSDg4O6t69uz744ANVqFDB2uf555/XU089dddlLVq0SLt379auXbsyTIuLi5OLi4vy589v016kSBHFxcVZ+9wcuNOnp0+7U5/ExERdvXpV7u7uGdadlJRkc516YmKiJCktLU1paWl33a5s5cAN6ZHL5PR9CgCAhwXDROQ2OXyYaG82zHLofuqpp9SkSRPNmDFDbdq0kbOzc4Y+pUuXVqdOne64nL///luvvPKKIiMj5ebmltUyTDVx4kSNGzcuQ/uZM2d07dq1bKgoCwIDs7sCIGtOn87uCgAAeDQwTERuk8OHiRcvXrSrX5ZCd2pqqubMmaPnnntOBQoUuG2/PHnyKDw8/I7Lio6O1unTp1W9enWb5f/www/6+OOPtW7dOiUnJys+Pt7maPepU6fk6+srSfL19dXOnTttlpt+d/Ob+9x6x/NTp07J09Mz06PckjRq1CgNGzbM+joxMVF+fn7y9vbO+dd0R0dndwVA1vj4ZHcFAAA8GhgmIrfJ4cNEew8eZyl0Ozo66qWXXlK9evXuGLrt0ahRI+3du9emrWfPnqpQoYJGjhwpPz8/OTs7a8OGDWrbtq0k6fDhw4qNjVVQUJAkKSgoSG+//bZOnz4tn/8/cI+MjJSnp6cCAgKsfb777jub9URGRlqXkRlXV1e5urpmaHdwcJBDTj99m1N1kdvk9H0KAICHBcNE5DY5fJhobzbM8unllSpV0p9//qnSpUtnuaib5cuXT5UqVbJpy5MnjwoVKmRt7927t4YNG6aCBQvK09NTgwYNUlBQkGrVqiVJatq0qQICAtStWzdNnjxZcXFxevPNNxUWFmYNzf3799fHH3+s1157Tb169dLGjRu1ePFirV69+l/VDwAAAADA3WT5u4O33npLw4cP16pVq3Ty5EklJiba/NxPH3zwgVq2bKm2bduqXr168vX11dKlS63THR0dtWrVKjk6OiooKEhdu3ZV9+7dNX78eGuf0qVLa/Xq1YqMjFTVqlX1/vvva9asWQoODr6vtQIAAAAAcKssP6f75kPoNz+H2zAMWSwWpaam3r/qcgie0w2YiOd0AwDwYDBMRG6Tw4eJ9ubELJ9evmnTpn9VGAAAAAAAj4osh+769eubUQcAAAAAAA+dLIduSYqPj9fs2bN18OBBSVLFihXVq1cveXl53dfiAAAAAADIzbJ8I7Wff/5ZZcqU0QcffKDz58/r/PnzmjJlisqUKaPdu3ebUSMAAAAAALlSlm+k9swzz6hs2bL6/PPP5eR040D59evX1adPH/3555/64YcfTCk0O3EjNcBE3EgNAIAHg2EicpscPky0NydmOXS7u7vrl19+UYUKFWzaDxw4oBo1aujKlSv3VnEORugGTEToBgDgwWCYiNwmhw8T7c2JWT693NPTU7GxsRna//77b+XLly+riwMAAAAA4KGV5dDdsWNH9e7dW1999ZX+/vtv/f3331q0aJH69Omjzp07m1EjAAAAAAC5UpbvXv7ee+/JYrGoe/fuun79uiTJ2dlZAwYM0KRJk+57gQAAAAAA5FZZvqY73ZUrV/THH39IksqUKSMPD4/7WlhOwjXdgIm4phsAgAeDYSJymxw+TLQ3J97Tc7olycPDQ5UrV77X2QEAAAAAeOhlOXRfu3ZNH330kTZt2qTTp08rLS3NZjrP6gYAAAAA4IYsh+7evXvr+++/V7t27fT000/LwunMAAAAAABkKsuhe9WqVfruu+9Up04dM+oBAAAAAOChkeVHhj322GM8jxsAAAAAADtkOXS///77GjlypI4dO2ZGPQAAAAAAPDSyfHp5jRo1dO3aNT3++OPy8PCQs7OzzfTz58/ft+IAAAAAAMjNshy6O3furOPHj2vChAkqUqQIN1IDAAAAAOA2shy6t2/frqioKFWtWtWMegAAAAAAeGhk+ZruChUq6OrVq2bUAgAAAADAQyXLoXvSpEl69dVXtXnzZp07d06JiYk2PwAAAAAA4AaLYRhGVmZwcLiR02+9ltswDFksFqWmpt6/6nKIxMREeXl5KSEhQZ6entldzp1xjT1ym6z9CgIAAPeKYSJymxw+TLQ3J2b5mu5Nmzb9q8IAAAAAAHhUZDl0169f34w6AAAAAAB46GT5mm5J+vHHH9W1a1fVrl1bx48flyTNmzdPW7duva/FAQAAAACQm2U5dH/zzTcKDg6Wu7u7du/eraSkJElSQkKCJkyYcN8LBAAAAAAgt8py6H7rrbc0c+ZMff7553J2dra216lTR7t3776vxQEAAAAAkJtlOXQfPnxY9erVy9Du5eWl+Pj4+1ETAAAAAAAPhSyHbl9fX/3+++8Z2rdu3arHH3/8vhQFAAAAAMDDIMuhu2/fvnrllVe0Y8cOWSwWnThxQgsWLNDw4cM1YMAAM2oEAAAAACBXyvIjw15//XWlpaWpUaNGunLliurVqydXV1cNHz5cgwYNMqNGAAAAAAByJYthGMa9zJicnKzff/9dly5dUkBAgPLmzXu/a8sxEhMT5eXlpYSEBHl6emZ3OXdmsWR3BUDW3NuvIAAAkFUME5Hb5PBhor05MctHutO5uLgoICDgXmcHAAAAAOChZ3fo7tWrl1395syZc8/FAAAAAADwMLE7dEdERKhkyZKqVq2a7vGMdAAAAAAAHil2h+4BAwboyy+/1NGjR9WzZ0917dpVBQsWNLM2AAAAAAByNbsfGfbJJ5/o5MmTeu2117Ry5Ur5+fmpQ4cOWrduHUe+AQAAAADIxD3fvfzYsWOKiIjQF198oevXr2v//v0P7R3MuXs5YCK+tAMA4MFgmIjcJocPE+3NiXYf6c4wo4ODLBaLDMNQamrqvS4GAAAAAICHVpZCd1JSkr788ks1adJE5cqV0969e/Xxxx8rNjb2oT3KDQAAAADAvbL7Rmovv/yyFi1aJD8/P/Xq1UtffvmlChcubGZtAAAAAADkanZf0+3g4KASJUqoWrVqstzhuuGlS5fet+JyCq7pBkzENd0AADwYDBOR2+TwYaK9OdHuI93du3e/Y9gGAAAAAAC27A7dERERJpYBAAAAAMDD557vXg4AAAAAAO6M0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYJFtD94wZM1SlShV5enrK09NTQUFBWrNmjXX6tWvXFBYWpkKFCilv3rxq27atTp06ZbOM2NhYhYSEyMPDQz4+PhoxYoSuX79u02fz5s2qXr26XF1dVbZsWUVERDyIzQMAAAAAPOKyNXQXL15ckyZNUnR0tH7++Wc9++yzat26tfbv3y9JGjp0qFauXKklS5Zoy5YtOnHihF544QXr/KmpqQoJCVFycrK2b9+uuXPnKiIiQqNHj7b2OXr0qEJCQtSwYUPFxMRoyJAh6tOnj9atW/fAtxcAAAAA8GixGIZhZHcRNytYsKDeffddtWvXTt7e3lq4cKHatWsnSTp06JD8/f0VFRWlWrVqac2aNWrZsqVOnDihIkWKSJJmzpypkSNH6syZM3JxcdHIkSO1evVq7du3z7qOTp06KT4+XmvXrrWrpsTERHl5eSkhIUGenp73f6PvJ4sluysAsiZn/QoCAODhxTARuU0OHybamxNzzDXdqampWrRokS5fvqygoCBFR0crJSVFjRs3tvapUKGCSpQooaioKElSVFSUKleubA3ckhQcHKzExETr0fKoqCibZaT3SV8GAAAAAABmccruAvbu3augoCBdu3ZNefPm1bJlyxQQEKCYmBi5uLgof/78Nv2LFCmiuLg4SVJcXJxN4E6fnj7tTn0SExN19epVubu7Z6gpKSlJSUlJ1teJiYmSpLS0NKWlpf27DTabQ475HgWwT07fpwAAeFgwTERuk8OHifZmw2wP3eXLl1dMTIwSEhL09ddfKzQ0VFu2bMnWmiZOnKhx48ZlaD9z5oyuXbuWDRVlQWBgdlcAZM3p09ldAQAAjwaGichtcvgw8eLFi3b1y/bQ7eLiorJly0qSAgMDtWvXLk2bNk0dO3ZUcnKy4uPjbY52nzp1Sr6+vpIkX19f7dy502Z56Xc3v7nPrXc8P3XqlDw9PTM9yi1Jo0aN0rBhw6yvExMT5efnJ29v75x/TXd0dHZXAGSNj092VwAAwKOBYSJymxw+THRzc7OrX7aH7lulpaUpKSlJgYGBcnZ21oYNG9S2bVtJ0uHDhxUbG6ugoCBJUlBQkN5++22dPn1aPv9/4B4ZGSlPT08FBARY+3z33Xc264iMjLQuIzOurq5ydXXN0O7g4CCHnH76NqfqIrfJ6fsUAAAPC4aJyG1y+DDR3myYraF71KhRat68uUqUKKGLFy9q4cKF2rx5s9atWycvLy/17t1bw4YNU8GCBeXp6alBgwYpKChItWrVkiQ1bdpUAQEB6tatmyZPnqy4uDi9+eabCgsLs4bm/v376+OPP9Zrr72mXr16aePGjVq8eLFWr16dnZsOAAAAAHgEZGvoPn36tLp3766TJ0/Ky8tLVapU0bp169SkSRNJ0gcffCAHBwe1bdtWSUlJCg4O1vTp063zOzo6atWqVRowYICCgoKUJ08ehYaGavz48dY+pUuX1urVqzV06FBNmzZNxYsX16xZsxQcHPzAtxcAAAAA8GjJcc/pzol4TjdgIn4FAQDwYDBMRG6Tw4eJue453QAAAAAAPGwI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmCRbQ/fEiRP11FNPKV++fPLx8VGbNm10+PBhmz7Xrl1TWFiYChUqpLx586pt27Y6deqUTZ/Y2FiFhITIw8NDPj4+GjFihK5fv27TZ/PmzapevbpcXV1VtmxZRUREmL15AAAAAIBHXLaG7i1btigsLEw//fSTIiMjlZKSoqZNm+ry5cvWPkOHDtXKlSu1ZMkSbdmyRSdOnNALL7xgnZ6amqqQkBAlJydr+/btmjt3riIiIjR69Ghrn6NHjyokJEQNGzZUTEyMhgwZoj59+mjdunUPdHsBAAAAAI8Wi2EYRnYXke7MmTPy8fHRli1bVK9ePSUkJMjb21sLFy5Uu3btJEmHDh2Sv7+/oqKiVKtWLa1Zs0YtW7bUiRMnVKRIEUnSzJkzNXLkSJ05c0YuLi4aOXKkVq9erX379lnX1alTJ8XHx2vt2rV3rSsxMVFeXl5KSEiQp6enORt/v1gs2V0BkDU551cQAAAPN4aJyG1y+DDR3pzo9ABruquEhARJUsGCBSVJ0dHRSklJUePGja19KlSooBIlSlhDd1RUlCpXrmwN3JIUHBysAQMGaP/+/apWrZqioqJslpHeZ8iQIZnWkZSUpKSkJOvrxMRESVJaWprS0tLuy7aaxoHL9JHL5PR9CgCAhwXDROQ2OXyYaG82zDGhOy0tTUOGDFGdOnVUqVIlSVJcXJxcXFyUP39+m75FihRRXFyctc/NgTt9evq0O/VJTEzU1atX5e7ubjNt4sSJGjduXIYaz5w5o2vXrt37Rj4IgYHZXQGQNadPZ3cFAAA8GhgmIrfJ4cPEixcv2tUvx4TusLAw7du3T1u3bs3uUjRq1CgNGzbM+joxMVF+fn7y9vbO+aeXR0dndwVA1vj4ZHcFAAA8GhgmIrfJ4cNENzc3u/rliNA9cOBArVq1Sj/88IOKFy9ubff19VVycrLi4+NtjnafOnVKvr6+1j47d+60WV763c1v7nPrHc9PnTolT0/PDEe5JcnV1VWurq4Z2h0cHOSQ00/f5lRd5DY5fZ8CAOBhwTARuU0OHybamw2zdTMMw9DAgQO1bNkybdy4UaVLl7aZHhgYKGdnZ23YsMHadvjwYcXGxiooKEiSFBQUpL179+r0TaeoRkZGytPTUwEBAdY+Ny8jvU/6MgAAAAAAMEO23r385Zdf1sKFC/Xtt9+qfPny1nYvLy/rEegBAwbou+++U0REhDw9PTVo0CBJ0vbt2yXdeGTYk08+qWLFimny5MmKi4tTt27d1KdPH02YMEHSjUeGVapUSWFhYerVq5c2btyowYMHa/Xq1QoODr5rndy9HDARdy8HAODBYJiI3CaHDxPtzYnZGrottwmI4eHh6tGjhyTp2rVrevXVV/Xll18qKSlJwcHBmj59uvXUcUk6duyYBgwYoM2bNytPnjwKDQ3VpEmT5OT0f2fPb968WUOHDtWBAwdUvHhx/fe//7Wu424I3YCJCN0AADwYDBOR2+TwYWKuCN25BaEbMBG/ggAAeDAYJiK3yeHDRHtzYg6/NB0AAAAAgNyL0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJgkW0P3Dz/8oFatWqlYsWKyWCxavny5zXTDMDR69GgVLVpU7u7uaty4sY4cOWLT5/z58+rSpYs8PT2VP39+9e7dW5cuXbLps2fPHj3zzDNyc3OTn5+fJk+ebPamAQAAAACQvaH78uXLqlq1qj755JNMp0+ePFkffvihZs6cqR07dihPnjwKDg7WtWvXrH26dOmi/fv3KzIyUqtWrdIPP/ygfv36WacnJiaqadOmKlmypKKjo/Xuu+9q7Nix+uyzz0zfPgAAAADAo81iGIaR3UVIksVi0bJly9SmTRtJN45yFytWTK+++qqGDx8uSUpISFCRIkUUERGhTp066eDBgwoICNCuXbtUo0YNSdLatWvVokUL/fPPPypWrJhmzJihN954Q3FxcXJxcZEkvf7661q+fLkOHTpkV22JiYny8vJSQkKCPD097//G308WS3ZXAGRNzvgVBADAw49hInKbHD5MtDcnOj3AmrLk6NGjiouLU+PGja1tXl5eqlmzpqKiotSpUydFRUUpf/781sAtSY0bN5aDg4N27Nih559/XlFRUapXr541cEtScHCw3nnnHV24cEEFChTIsO6kpCQlJSVZXycmJkqS0tLSlJaWZsbm3j8OXKaPXCan71MAADwsGCYit8nhw0R7s2GODd1xcXGSpCJFiti0FylSxDotLi5OPj4+NtOdnJxUsGBBmz6lS5fOsIz0aZmF7okTJ2rcuHEZ2s+cOWNzanuOFBiY3RUAWXP6dHZXAADAo4FhInKbHD5MvHjxol39cmzozk6jRo3SsGHDrK8TExPl5+cnb2/vnH96eXR0dlcAZM0tX5wBAACTMExEbpPDh4lubm529cuxodvX11eSdOrUKRUtWtTafurUKT355JPWPqdvOUp2/fp1nT9/3jq/r6+vTp06ZdMn/XV6n1u5urrK1dU1Q7uDg4Mccvrp25yqi9wmp+9TAAA8LBgmIrfJ4cNEe7Nhjt2M0qVLy9fXVxs2bLC2JSYmaseOHQoKCpIkBQUFKT4+XtE3Hd3duHGj0tLSVLNmTWufH374QSkpKdY+kZGRKl++fKanlgMAAAAAcL9ka+i+dOmSYmJiFBMTI+nGzdNiYmIUGxsri8WiIUOG6K233tKKFSu0d+9ede/eXcWKFbPe4dzf31/NmjVT3759tXPnTm3btk0DBw5Up06dVKxYMUnSiy++KBcXF/Xu3Vv79+/XV199pWnTptmcPg4AAAAAgBmy9ZFhmzdvVsOGDTO0h4aGKiIiQoZhaMyYMfrss88UHx+vunXravr06SpXrpy17/nz5zVw4ECtXLlSDg4Oatu2rT788EPlzZvX2mfPnj0KCwvTrl27VLhwYQ0aNEgjR460u04eGQaYiEeGAQDwYDBMRG6Tw4eJ9ubEHPOc7pyM0A2YiF9BAAA8GAwTkdvk8GGivTkxx17TDQAAAABAbkfoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AQKbGjh0ri8Vi81OhQoU7zhMREZFhHjc3t9v279+/vywWi6ZOnXrH5fbo0UMWi0X9+/fPMC0sLEwWi0U9evTI0D/9p1ChQmrWrJn27Nlzx/UAD8rEiRP11FNPKV++fPLx8VGbNm10+PDhO87ToEGDDPuXxWJRSEiItc/SpUvVtGlTFSpUSBaLRTExMXetJX1fb9asWYZp7777riwWixo0aJChf/qPl5eXnnnmGW3ZssXu7QeARwmhGwBwWxUrVtTJkyetP1u3br3rPJ6enjbzHDt2LNN+y5Yt008//aRixYrZVYufn58WLVqkq1evWtuuXbumhQsXqkSJEhn6N2vWzFrDhg0b5OTkpJYtW9q1LsBsW7ZsUVhYmH766SdFRkYqJSVFTZs21eXLl287z9KlS232rX379snR0VHt27e39rl8+bLq1q2rd955J0v1FC1aVJs2bdI///xj0z5nzpxM96+bfzdERUXpiSeeUMuWLZWQkJCl9QLAo8ApuwsAAORcTk5O8vX1zdI8FovlrvMcP35cgwYN0rp162yO0t1J9erV9ccff2jp0qXq0qWLpBshpESJEipdunSG/q6urtY6fH199frrr+uZZ57RmTNn5O3tnaVtAu63tWvX2ryOiIiQj4+PoqOjVa9evUznKViwoM3rRYsWycPDwyZ0d+vWTZL0119/ZakeHx8fBQYGau7cuXrjjTckSdu3b9fZs2fVvn17HThwwKb/zb8bfH19NX78eIWHh+u3337TU089laV1A8DDjiPdAIDbOnLkiIoVK6bHH39cXbp0UWxs7F3nuXTpkkqWLCk/Pz+1bt1a+/fvt5melpambt26acSIEapYsWKW6unVq5fCw8Otr+fMmaOePXvaVdP8+fNVtmxZFSpUKEvrBB6E9CPEtwbrO5k9e7Y6deqkPHny3JcaevXqpYiICOvrOXPmqEuXLnJxcbnjfElJSQoPD1f+/PlVvnz5+1ILADxMCN0AgEzVrFlTERERWrt2rWbMmKGjR4/qmWee0cWLF287T/ny5TVnzhx9++23mj9/vtLS0lS7dm2bU1bfeecdOTk5afDgwVmuqWvXrtq6dauOHTumY8eOadu2beratWumfVetWqW8efMqb968ypcvn1asWKGvvvpKDg786UPOkpaWpiFDhqhOnTqqVKmSXfPs3LlT+/btU58+fe5bHS1btlRiYqJ++OEHXb58WYsXL1avXr0y7bt3717r/uXu7q733ntPX375pTw9Pe9bPQDwsOD0cgBAppo3b279/ypVqqhmzZoqWbKkFi9erN69e2c6T1BQkIKCgqyva9euLX9/f3366af63//+p+joaE2bNk27d++WxWLJck3e3t4KCQlRRESEDMNQSEiIChcunGnfhg0basaMGZKkCxcuaPr06WrevLl27typkiVLZnndgFnCwsK0b98+u+6ZkG727NmqXLmynn766ftWh7Ozs7p27arw8HD9+eefKleunKpUqZJp3/Lly2vFihWSpIsXL+qrr75S+/bttWnTJtWoUeO+1QQADwNCNwDALvnz51e5cuX0+++/2z2Ps7OzqlWrZp3nxx9/1OnTp21uzJSamqpXX31VU6dOtes61F69emngwIGSpE8++eS2/fLkyaOyZctaX8+aNUteXl76/PPP9dZbb9m9DYCZBg4cqFWrVumHH35Q8eLF7Zrn8uXLWrRokcaPH3/f6+nVq5dq1qypffv23fYotyS5uLjY7F/VqlXT8uXLNXXqVM2fP/++1wUAuRnn2AEA7HLp0iX98ccfKlq0qN3zpKamau/evdZ5unXrpj179igmJsb6U6xYMY0YMULr1q2za5nNmjVTcnKyUlJSFBwcbHctFotFDg4ONnc/B7KLYRgaOHCgli1bpo0bN2Z6M8DbWbJkiZKSkm57acW/UbFiRVWsWFH79u3Tiy++mKV5HR0d2b8AIBMc6QYAZGr48OFq1aqVSpYsqRMnTmjMmDFydHRU586drX26d++uxx57TBMnTpQkjR8/XrVq1VLZsmUVHx+vd999V8eOHbNed1qoUKEMNzJzdnaWr6+v3TdgcnR01MGDB63/fztJSUmKi4uTdOP08o8//liXLl1Sq1at7H8TAJOEhYVp4cKF+vbbb5UvXz7rZ9XLy0vu7u6SMu5f6WbPnq02bdpkelPA8+fPKzY2VidOnJAk67O/fX197X4SwcaNG5WSkqL8+fPfts/169etNaefXn7gwAGNHDnSrnUAwKPkkQrdn3zyid59913FxcWpatWq+uijj+7rtVAA8DD5559/1LlzZ507d07e3t6qW7eufvrpJ5vHbcXGxtrcmOzChQvq27ev4uLiVKBAAQUGBmr79u0KCAi4r7XZc7OmtWvXWo+w58uXTxUqVNCSJUvUoEGD+1oLcC/S7zdw6+cxPDxcPXr0kJRx/5JuhOitW7fq+++/z3S5K1assLmjf6dOnSRJY8aM0dixY+2qzZ67oe/fv9+6f3l4eKhMmTKaMWOGunfvbtc6AOBRYjEMw8juIh6Er776St27d9fMmTNVs2ZNTZ06VUuWLNHhw4fl4+Nzx3kTExPl5eWlhISEnH9Xznu4MRGQrR6NX0EAAGQ/honIbXL4MNHenPjIXNM9ZcoU9e3bVz179lRAQIBmzpwpDw8PzZkzJ7tLAwAAAAA8pB6J08uTk5MVHR2tUaNGWdscHBzUuHFjRUVFZeiflJSkpKQk6+uEhARJUnx8vNLS0swv+N/gSDdym/j47K4AAIBHA8NE5Dbx2V3AnSUmJkq6cXPMO3kkQvfZs2eVmpqqIkWK2LQXKVJEhw4dytB/4sSJGjduXIZ2nusKmKBAgeyuAAAAADlRLhkmXrx4UV5eXred/kiE7qwaNWqUhg0bZn2dlpam8+fPq1ChQrJwJPmRk5iYKD8/P/399985/5p+IBdiHwPMxT4GmIf969FmGIYuXryoYsWK3bHfIxG6CxcuLEdHR506dcqm/dSpU5k+PsPV1VWurq42bXd6bAYeDZ6envwyBUzEPgaYi30MMA/716PrTke40z0SN1JzcXFRYGCgNmzYYG1LS0vThg0bFBQUlI2VAQAAAAAeZo/EkW5JGjZsmEJDQ1WjRg09/fTTmjp1qi5fvmzzLEsAAAAAAO6nRyZ0d+zYUWfOnNHo0aMVFxenJ598UmvXrs1wczXgVq6urhozZkyGSw4A3B/sY4C52McA87B/wR4W4273NwcAAAAAAPfkkbimGwAAAACA7EDoBgAAAADAJIRuAAAAAABMQujGI2Xz5s2yWCyKj4+3e55SpUpp6tSpptV0rywWi5YvX57dZQAPLfYxIKOIiAjlz58/u8sAcp0GDRpoyJAh2V0GsgmhGzlGjx49ZLFY1L9//wzTwsLCZLFY1KNHjwdf2F2MHTtWTz75ZHaXgYdcjx491KZNmwe+XnsH2BEREbJYLLJYLHJwcFDx4sXVs2dPnT592vwiTXLy5Ek1b948u8tALhUXF6dXXnlFZcuWlZubm4oUKaI6depoxowZunLlSnaXZ5fMvnTu2LGjfvvtt+wpCDBR+jjUYrHIxcVFZcuW1fjx43X9+vXsLg0PgUfmkWHIHfz8/LRo0SJ98MEHcnd3lyRdu3ZNCxcuVIkSJbK5OgB34unpqcOHDystLU2//vqrevbsqRMnTmjdunUZ+qamploDek7l6+ub3SUgl/rzzz9Vp04d5c+fXxMmTFDlypXl6uqqvXv36rPPPtNjjz2m5557LltqMwxDqampcnK6tyGgu7u79e8z8LBp1qyZwsPDlZSUpO+++05hYWFydnbWqFGjsrs05HI5d7SDR1L16tXl5+enpUuXWtuWLl2qEiVKqFq1ajZ9k5KSNHjwYPn4+MjNzU1169bVrl27bPp89913KleunNzd3dWwYUP99ddfGda5detWPfPMM3J3d5efn58GDx6sy5cv37dt2rt3r5599lm5u7urUKFC6tevny5dumSdvmvXLjVp0kSFCxeWl5eX6tevr927d9ss48iRI6pXr57c3NwUEBCgyMjI+1YfcqcGDRpo8ODBeu2111SwYEH5+vpq7NixNn0sFotmzJih5s2by93dXY8//ri+/vpr6/TMLreIiYmRxWLRX3/9pc2bN6tnz55KSEiwfvt/6zpuXZ+vr6+KFSum5s2ba/DgwVq/fr2uXr1qPWK+YsUKBQQEyNXVVbGxsbpw4YK6d++uAgUKyMPDQ82bN9eRI0dslrtt2zY1aNBAHh4eKlCggIKDg3XhwgVJUlpamiZOnKjSpUvL3d1dVatWtdnGCxcuqEuXLvL29pa7u7ueeOIJhYeHS5KSk5M1cOBAFS1aVG5ubipZsqQmTpxosz3pp5f/9ddfslgsWrp0qRo2bCgPDw9VrVpVUVFRNrV+/vnn8vPzk4eHh55//nlNmTKFU3EfQS+//LKcnJz0888/q0OHDvL399fjjz+u1q1ba/Xq1WrVqpUkKT4+Xn369JG3t7c8PT317LPP6tdff7UuJ/1Mqnnz5qlUqVLy8vJSp06ddPHiRWufu+0D6fv5mjVrFBgYKFdXV23dulV//PGHWrdurSJFiihv3rx66qmntH79eut8DRo00LFjxzR06FDr/i9lfvbLjBkzVKZMGbm4uKh8+fKaN2+ezXSLxaJZs2bp+eefl4eHh5544gmtWLHivr3fwP3i6uoqX19flSxZUgMGDFDjxo21YsUKJSUlafjw4XrssceUJ08e1axZU5s3b7bOd+7cOXXu3FmPPfaYPDw8VLlyZX355Zd3XNfq1avl5eWlBQsWmLxVyAkI3chxevXqZR0US9KcOXPUs2fPDP1ee+01ffPNN5o7d652796tsmXLKjg4WOfPn5ck/f3333rhhRfUqlUrxcTEqE+fPnr99ddtlvHHH3+oWbNmatu2rfbs2aOvvvpKW7du1cCBA+/Ltly+fFnBwcEqUKCAdu3apSVLlmj9+vU2y7948aJCQ0O1detW/fTTT3riiSfUokUL66AqLS1NL7zwglxcXLRjxw7NnDlTI0eOvC/1IXebO3eu8uTJox07dmjy5MkaP358hi9k/vvf/6pt27b69ddf1aVLF3Xq1EkHDx60a/m1a9fW1KlT5enpqZMnT+rkyZMaPny43fW5u7srLS3NemrelStX9M4772jWrFnav3+/fHx81KNHD/38889asWKFoqKiZBiGWrRooZSUFEk3vgRo1KiRAgICFBUVpa1bt6pVq1ZKTU2VJE2cOFFffPGFZs6cqf3792vo0KHq2rWrtmzZYt3+AwcOaM2aNTp48KBmzJihwoULS5I+/PBDrVixQosXL9bhw4e1YMEClSpV6o7b9MYbb2j48OGKiYlRuXLl1LlzZ+v2bdu2Tf3799crr7yimJgYNWnSRG+//bbd7xceDufOndP333+vsLAw5cmTJ9M+6QG2ffv2On36tNasWaPo6GhVr15djRo1sv4dk278nVq+fLlWrVqlVatWacuWLZo0aZJ1+t32gXSvv/66Jk2apIMHD6pKlSq6dOmSWrRooQ0bNuiXX35Rs2bN1KpVK8XGxkq68YV38eLFNX78eOv+n5lly5bplVde0auvvqp9+/bppZdeUs+ePbVp0yabfuPGjVOHDh20Z88etWjRQl26dLHZTiAncnd3t35BGxUVpUWLFmnPnj1q3769mjVrZv2S+Nq1awoMDNTq1au1b98+9evXT926ddPOnTszXe7ChQvVuXNnLViwQF26dHmQm4TsYgA5RGhoqNG6dWvj9OnThqurq/HXX38Zf/31l+Hm5macOXPGaN26tREaGmoYhmFcunTJcHZ2NhYsWGCdPzk52ShWrJgxefJkwzAMY9SoUUZAQIDNOkaOHGlIMi5cuGAYhmH07t3b6Nevn02fH3/80XBwcDCuXr1qGIZhlCxZ0vjggw9uW/eYMWOMqlWrZjrts88+MwoUKGBcunTJ2rZ69WrDwcHBiIuLy3Se1NRUI1++fMbKlSsNwzCMdevWGU5OTsbx48etfdasWWNIMpYtW3bbuvBwSd8/0tWvX9+oW7euTZ+nnnrKGDlypPW1JKN///42fWrWrGkMGDDAMAzD2LRpk83+YBiG8csvvxiSjKNHjxqGYRjh4eGGl5fXXeu7td9vv/1mlCtXzqhRo4Z1uiQjJibGpo8kY9u2bda2s2fPGu7u7sbixYsNwzCMzp07G3Xq1Ml0ndeuXTM8PDyM7du327T37t3b6Ny5s2EYhtGqVSujZ8+emc4/aNAg49lnnzXS0tIynX7zPnb06FFDkjFr1izr9P379xuSjIMHDxqGYRgdO3Y0QkJCbJbRpUsXu94/PDx++uknQ5KxdOlSm/ZChQoZefLkMfLkyWO89tprxo8//mh4enoa165ds+lXpkwZ49NPPzUM48bfFw8PDyMxMdE6fcSIEUbNmjUNw7BvH0jfz5cvX37X2itWrGh89NFH1teZ/f27dV+vXbu20bdvX5s+7du3N1q0aGF9Lcl48803ra8vXbpkSDLWrFlz15qAB+Xmv7NpaWlGZGSk4erqavTo0cNwdHS0GYcZhmE0atTIGDVq1G2XFxISYrz66qvW1/Xr1zdeeeUV4+OPPza8vLyMzZs3m7IdyJm4phs5jre3t0JCQhQRESHDMBQSEmI9MpXujz/+UEpKiurUqWNtc3Z21tNPP209infw4EHVrFnTZr6goCCb17/++qv27Nljc2qPYRhKS0vT0aNH5e/v/6+25eDBg6patarN0Y46deooLS1Nhw8fVpEiRXTq1Cm9+eab2rx5s06fPq3U1FRduXLFerTh4MGD8vPzU7FixW67HXg0ValSxeZ10aJFM9y47NbPSlBQkGJiYkypJyEhQXnz5lVaWpquXbumunXratasWdbpLi4uNjUfPHhQTk5ONvtpoUKFVL58eet+HBMTo/bt22e6vt9//11XrlxRkyZNbNqTk5Otl6MMGDBAbdu21e7du9W0aVO1adNGtWvXlnTjpjlNmjRR+fLl1axZM7Vs2VJNmza94zbeXH/RokUlSadPn1aFChV0+PBhPf/88zb9n376aa1ateqOy8SjYefOnUpLS1OXLl2UlJSkX3/9VZcuXVKhQoVs+l29elV//PGH9XWpUqWUL18+6+ub93N79oF0NWrUsHl96dIljR07VqtXr9bJkyd1/fp1Xb161fq3x14HDx5Uv379bNrq1KmjadOm2bTdvO/kyZNHnp6eufpGi3g4rVq1Snnz5lVKSorS0tL04osvql27doqIiFC5cuVs+iYlJVn339TUVE2YMEGLFy/W8ePHlZycrKSkJHl4eNjM8/XXX+v06dPatm2bnnrqqQe2Xch+hG7kSL169bKegv3JJ5+Ytp5Lly7ppZde0uDBgzNMe1A3bgsNDdW5c+c0bdo0lSxZUq6urgoKClJycvIDWT9yL2dnZ5vXFotFaWlpds+ffhMzwzCsbemndd+LfPnyaffu3XJwcFDRokUz3GzJ3d3delqtve50w6b0eyOsXr1ajz32mM00V1dXSVLz5s117Ngxfffdd4qMjFSjRo0UFham9957T9WrV9fRo0e1Zs0arV+/Xh06dFDjxo1troe91c3vefq2ZOU9x8OvbNmyslgsOnz4sE37448/Lun/PtOXLl1S0aJFba4LTXfzNdN32s/t2QfS3Xqq+/DhwxUZGan33ntPZcuWlbu7u9q1a2fa355/+/sKeBAaNmyoGTNmyMXFRcWKFZOTk5O++uorOTo6Kjo6Wo6Ojjb98+bNK0l69913NW3aNE2dOlWVK1dWnjx5NGTIkAz7U7Vq1bR7927NmTNHNWrUyPLfROReXNONHKlZs2ZKTk5WSkqKgoODM0xPv2HLtm3brG0pKSnatWuXAgICJEn+/v4ZrqX56aefbF5Xr15dBw4cUNmyZTP8uLi4/Ovt8Pf316+//mpzY7Zt27bJwcFB5cuXt74ePHiwWrRooYoVK8rV1VVnz561Wcbff/9tcz3drdsB3M6tn5WffvrJegaHt7e3JNl8tm49Cu7i4mK9fvpuHBwcVLZsWT3++ON23d3Y399f169f144dO6xt586d0+HDh637cZUqVbRhw4ZM57/5hmy37r9+fn7Wft7e3goNDdX8+fM1depUffbZZ9Zpnp6e6tixoz7//HN99dVX+uabb+75OtPy5ctnuJnjra/x8CtUqJCaNGmijz/++I435axevbri4uLk5OSU4fN769ldt2PvPpCZbdu2qUePHnr++edVuXJl+fr6ZrjZqD37v7+/v83f4vRlp+/DQG6SJ08elS1bViVKlLDe4b9atWpKTU3V6dOnM+xn6U+52LZtm1q3bq2uXbuqatWqevzxxzN9tF6ZMmW0adMmffvttxo0aNAD3TZkL450I0dydHS0nl5667eK0o1figMGDNCIESNUsGBBlShRQpMnT9aVK1fUu3dvSVL//v31/vvva8SIEerTp4+io6MVERFhs5yRI0eqVq1aGjhwoPr06aM8efLowIEDioyM1Mcff2x3vVevXs0QVvLly6cuXbpozJgxCg0N1dixY3XmzBkNGjRI3bp1U5EiRSRJTzzxhObNm6caNWooMTFRI0aMsAksjRs3Vrly5RQaGqp3331XiYmJeuONN+yuDY+2JUuWqEaNGqpbt64WLFignTt3avbs2ZJkHZiPHTtWb7/9tn777Te9//77NvOXKlVKly5d0oYNG1S1alV5eHhkOF3uXj3xxBNq3bq1+vbtq08//VT58uXT66+/rscee0ytW7eWJI0aNUqVK1fWyy+/rP79+8vFxUWbNm1S+/btVbhwYQ0fPlxDhw5VWlqa6tatq4SEBG3btk2enp4KDQ3V6NGjFRgYqIoVKyopKUmrVq2yfukwZcoUFS1aVNWqVZODg4OWLFkiX1/fe77b+KBBg1SvXj1NmTJFrVq10saNG7VmzRqOZDyCpk+frjp16qhGjRoaO3asqlSpIgcHB+3atUuHDh1SYGCgGjdurKCgILVp00aTJ09WuXLldOLECa1evVrPP/98htPBM5MvX7677gO388QTT2jp0qVq1aqVLBaL/vvf/2Y48lyqVCn98MMP6tSpk1xdXTP9MmDEiBHq0KGDqlWrpsaNG2vlypVaunSpzZ3QgdysXLly6tKli7p37673339f1apV05kzZ7RhwwZVqVJFISEheuKJJ/T1119r+/btKlCggKZMmaJTp05l+uVTuXLltGnTJjVo0EBOTk6aOnXqg98oPHAc6UaO5enpKU9Pz9tOnzRpktq2batu3bqpevXq+v3337Vu3ToVKFBA0o3Tw7/55hstX75cVatW1cyZMzVhwgSbZVSpUkVbtmzRb7/9pmeeeUbVqlXT6NGjba6ftsdvv/2matWq2fy89NJL8vDw0Lp163T+/Hk99dRTateunRo1amQT6GfPnq0LFy6oevXq6tatm/UxaOkcHBy0bNkyXb16VU8//bT69OnDHZFht3HjxmnRokWqUqWKvvjiC3355ZfWQYCzs7O+/PJLHTp0SFWqVNE777yjt956y2b+2rVrq3///urYsaO8vb01efLk+1pfeHi4AgMD1bJlSwUFBckwDH333XfWU1HLlSun77//Xr/++quefvppBQUF6dtvv7Uegfjf//6n//73v5o4caL8/f3VrFkzrV69WqVLl5Z040jdqFGjVKVKFdWrV0+Ojo5atGiRpBuBZfLkyapRo4aeeuop/fXXX/ruu+/u+dnhderU0cyZMzVlyhRVrVpVa9eu1dChQ+Xm5nYf3inkJmXKlNEvv/yixo0ba9SoUapatapq1Kihjz76SMOHD9f//vc/WSwWfffdd6pXr5569uypcuXKqVOnTjp27Jj1S1l73G0fuJ0pU6aoQIECql27tlr9v3buEEd1KArA8EGzATSIClxXUEOqJukKULCCWhSS1IAgQTUoJBKHwcEGkOyBBcxzkzeTzGTE3OnLy/fppjlXNX9ybl9eoizLyPP83TPL5TIej0eMRqO3zZiPqqqK9XodTdPEeDyO3W4XbdtGURTfPgP869q2jel0GnVdR5ZlUVVV3G63t6uIi8Ui8jyPsiyjKIoYDAZRVdWn78uyLM7ncxwOh6jr+pdOQZd6r39f5gPgv9Hr9eJ4PH754Set+Xwe9/s9LpdL16MAAB2xXg4AP6RpmphMJtHv9+N0OsV+v4/tdtv1WABAh0Q3APyQ6/Uaq9Uqns9nDIfD2Gw2MZvNuh4LAOiQ9XIAAABIxI/UAAAAIBHRDQAAAImIbgAAAEhEdAMAAEAiohsAAAASEd0AAACQiOgGAACAREQ3AAAAJCK6AQAAIJE/GuxLTcAm0KMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n",
    "\n",
    "# Configuration\n",
    "class CFG:\n",
    "    # Model paths\n",
    "    qwen_model_path = \"/kaggle/input/qwen2-vl/transformers/7b-instruct/1\"\n",
    "    \n",
    "    # Test image path - adjust if needed\n",
    "    test_image_path = \"/kaggle/input/ocr-receipts-text-detection/images/1.jpg\"\n",
    "    \n",
    "    # Output file\n",
    "    output_file = \"memory_analysis_results.json\"\n",
    "    \n",
    "    # Number of test runs\n",
    "    num_runs = 3\n",
    "    \n",
    "    # Maximum new tokens for generation\n",
    "    max_tokens = 1024\n",
    "\n",
    "def get_gpu_memory_info():\n",
    "    \"\"\"Get current GPU memory usage\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        # Get current device\n",
    "        device = torch.cuda.current_device()\n",
    "        \n",
    "        # Get memory information\n",
    "        mem_info = {\n",
    "            'allocated': torch.cuda.memory_allocated(device) / (1024 * 1024),  # MB\n",
    "            'reserved': torch.cuda.memory_reserved(device) / (1024 * 1024),    # MB\n",
    "            'max_allocated': torch.cuda.max_memory_allocated(device) / (1024 * 1024),  # MB\n",
    "            'max_reserved': torch.cuda.max_memory_reserved(device) / (1024 * 1024),   # MB\n",
    "            'total': torch.cuda.get_device_properties(device).total_memory / (1024 * 1024)  # MB\n",
    "        }\n",
    "        \n",
    "        # Get memory stats for each tensor\n",
    "        if hasattr(torch.cuda, 'memory_stats'):\n",
    "            mem_info['stats'] = {k: v / (1024 * 1024) for k, v in torch.cuda.memory_stats().items()}\n",
    "            \n",
    "        # Get memory summary\n",
    "        if hasattr(torch.cuda, 'memory_summary'):\n",
    "            mem_info['summary'] = torch.cuda.memory_summary()\n",
    "            \n",
    "        return mem_info\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def measure_model_memory(model_path, test_image_path, num_runs=3, max_tokens=1024):\n",
    "    \"\"\"Measure memory usage of a model during inference\"\"\"\n",
    "    results = {\n",
    "        'model': model_path,\n",
    "        'device': \"CPU\" if not torch.cuda.is_available() else f\"GPU:{torch.cuda.get_device_name(0)}\",\n",
    "        'runs': []\n",
    "    }\n",
    "    \n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    \n",
    "    # Check if CUDA is available\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"Warning: CUDA not available, using CPU only. Memory measurements will be minimal.\")\n",
    "        return results\n",
    "    \n",
    "    # Load test image\n",
    "    try:\n",
    "        test_image = Image.open(test_image_path)\n",
    "        print(f\"Loaded test image: {test_image_path}, size: {test_image.size}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading test image: {e}\")\n",
    "        return results\n",
    "    \n",
    "    # Reset CUDA memory stats\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Baseline memory before loading model\n",
    "    baseline_memory = get_gpu_memory_info()\n",
    "    results['baseline_memory'] = baseline_memory\n",
    "    print(f\"Baseline GPU Memory: {baseline_memory['allocated']:.2f} MB allocated, {baseline_memory['reserved']:.2f} MB reserved\")\n",
    "    \n",
    "    try:\n",
    "        # Load processor\n",
    "        processor = AutoProcessor.from_pretrained(model_path)\n",
    "        \n",
    "        # After processor memory\n",
    "        processor_memory = get_gpu_memory_info()\n",
    "        results['processor_memory'] = processor_memory\n",
    "        print(f\"After loading processor: {processor_memory['allocated']:.2f} MB allocated, {processor_memory['reserved']:.2f} MB reserved\")\n",
    "        \n",
    "        # Load model\n",
    "        model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "            model_path,\n",
    "            torch_dtype=torch.float16,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "        \n",
    "        # After model memory\n",
    "        model_memory = get_gpu_memory_info()\n",
    "        results['model_memory'] = model_memory\n",
    "        print(f\"After loading model: {model_memory['allocated']:.2f} MB allocated, {model_memory['reserved']:.2f} MB reserved\")\n",
    "        print(f\"Model size in memory: {model_memory['allocated'] - processor_memory['allocated']:.2f} MB\")\n",
    "        \n",
    "        # Create messages for the model\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\"},\n",
    "                    {\"type\": \"text\", \"text\": \"Extract all the text from this receipt image.\"}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Run inference multiple times and measure memory\n",
    "        for run in range(num_runs):\n",
    "            print(f\"\\nRun {run+1}/{num_runs}\")\n",
    "            \n",
    "            # Reset peak stats\n",
    "            torch.cuda.reset_peak_memory_stats()\n",
    "            \n",
    "            # Before inference memory\n",
    "            before_memory = get_gpu_memory_info()\n",
    "            \n",
    "            # Process input\n",
    "            start_time = time.time()\n",
    "            inputs = processor(\n",
    "                text=processor.apply_chat_template(messages, add_generation_prompt=True),\n",
    "                images=[test_image],\n",
    "                padding=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # Move inputs to device\n",
    "            inputs = inputs.to(model.device)\n",
    "            \n",
    "            # After input processing memory\n",
    "            input_memory = get_gpu_memory_info()\n",
    "            \n",
    "            # Generate output\n",
    "            with torch.no_grad():\n",
    "                try:\n",
    "                    output_ids = model.generate(**inputs, max_new_tokens=max_tokens)\n",
    "                    # Memory after generation\n",
    "                    generation_memory = get_gpu_memory_info()\n",
    "                    \n",
    "                    # Decode output (this shouldn't use much CUDA memory)\n",
    "                    _ = processor.batch_decode(\n",
    "                        output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "                    )[0]\n",
    "                    \n",
    "                    inference_time = time.time() - start_time\n",
    "                    \n",
    "                    # Final memory after full inference\n",
    "                    after_memory = get_gpu_memory_info()\n",
    "                    \n",
    "                    run_results = {\n",
    "                        'run_id': run + 1,\n",
    "                        'before_memory': before_memory,\n",
    "                        'input_memory': input_memory,\n",
    "                        'generation_memory': generation_memory,\n",
    "                        'after_memory': after_memory,\n",
    "                        'inference_time': inference_time,\n",
    "                        'memory_increase': {\n",
    "                            'input_processing': input_memory['allocated'] - before_memory['allocated'],\n",
    "                            'generation': generation_memory['allocated'] - input_memory['allocated'],\n",
    "                            'total': after_memory['allocated'] - before_memory['allocated']\n",
    "                        },\n",
    "                        'peak_memory': after_memory['max_allocated']\n",
    "                    }\n",
    "                    \n",
    "                    results['runs'].append(run_results)\n",
    "                    \n",
    "                    print(f\"Memory for input processing: {run_results['memory_increase']['input_processing']:.2f} MB\")\n",
    "                    print(f\"Memory for generation: {run_results['memory_increase']['generation']:.2f} MB\")\n",
    "                    print(f\"Total memory increase: {run_results['memory_increase']['total']:.2f} MB\")\n",
    "                    print(f\"Peak memory: {run_results['peak_memory']:.2f} MB\")\n",
    "                    print(f\"Inference time: {inference_time:.2f} seconds\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error during generation: {e}\")\n",
    "                    results['runs'].append({\n",
    "                        'run_id': run + 1,\n",
    "                        'error': str(e),\n",
    "                        'before_memory': before_memory\n",
    "                    })\n",
    "            \n",
    "            # Clear CUDA cache between runs\n",
    "            torch.cuda.empty_cache()\n",
    "            time.sleep(1)  # Small pause to let memory fully clear\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in memory measurement: {e}\")\n",
    "        results['error'] = str(e)\n",
    "    \n",
    "    # Calculate average memory usage across runs\n",
    "    if results['runs']:\n",
    "        valid_runs = [r for r in results['runs'] if 'error' not in r]\n",
    "        if valid_runs:\n",
    "            results['average'] = {\n",
    "                'input_processing_memory': np.mean([r['memory_increase']['input_processing'] for r in valid_runs]),\n",
    "                'generation_memory': np.mean([r['memory_increase']['generation'] for r in valid_runs]),\n",
    "                'total_memory_increase': np.mean([r['memory_increase']['total'] for r in valid_runs]),\n",
    "                'peak_memory': np.mean([r['peak_memory'] for r in valid_runs]),\n",
    "                'inference_time': np.mean([r['inference_time'] for r in valid_runs])\n",
    "            }\n",
    "            \n",
    "            print(\"\\nAverage across runs:\")\n",
    "            print(f\"Input processing memory: {results['average']['input_processing_memory']:.2f} MB\")\n",
    "            print(f\"Generation memory: {results['average']['generation_memory']:.2f} MB\")\n",
    "            print(f\"Total memory increase: {results['average']['total_memory_increase']:.2f} MB\")\n",
    "            print(f\"Peak memory: {results['average']['peak_memory']:.2f} MB\")\n",
    "            print(f\"Inference time: {results['average']['inference_time']:.2f} seconds\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "def plot_memory_usage(results, output_path=\"memory_usage.png\"):\n",
    "    \"\"\"Create a visualization of memory usage\"\"\"\n",
    "    valid_runs = [r for r in results['runs'] if 'error' not in r]\n",
    "    if not valid_runs:\n",
    "        print(\"No valid runs to plot\")\n",
    "        return\n",
    "    \n",
    "    # Extract relevant memory data\n",
    "    run_ids = [r['run_id'] for r in valid_runs]\n",
    "    baseline = results['baseline_memory']['allocated'] if 'baseline_memory' in results else 0\n",
    "    model_load = results['model_memory']['allocated'] if 'model_memory' in results else 0\n",
    "    input_proc = [baseline + r['memory_increase']['input_processing'] for r in valid_runs]\n",
    "    generation = [baseline + r['memory_increase']['input_processing'] + r['memory_increase']['generation'] for r in valid_runs]\n",
    "    peak = [r['peak_memory'] for r in valid_runs]\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    \n",
    "    # Model loading memory (constant across runs)\n",
    "    plt.axhline(y=model_load, color='r', linestyle='-', label=f'Model Loaded ({model_load:.2f} MB)')\n",
    "    \n",
    "    # Memory used in each stage\n",
    "    plt.plot(run_ids, input_proc, 'go-', label='After Input Processing')\n",
    "    plt.plot(run_ids, generation, 'bo-', label='After Generation')\n",
    "    plt.plot(run_ids, peak, 'mo-', label='Peak Memory')\n",
    "    \n",
    "    plt.xlabel('Run Number')\n",
    "    plt.ylabel('Memory (MB)')\n",
    "    plt.title('GPU Memory Usage During Inference')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    print(f\"Memory usage plot saved to {output_path}\")\n",
    "    \n",
    "    # Also create a bar chart for average memory\n",
    "    avg = results['average']\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    stages = ['Model Load', 'Input Processing', 'Generation', 'Peak']\n",
    "    memory_values = [\n",
    "        model_load - baseline,\n",
    "        avg['input_processing_memory'],\n",
    "        avg['generation_memory'],\n",
    "        avg['peak_memory'] - baseline\n",
    "    ]\n",
    "    \n",
    "    plt.bar(stages, memory_values, color=['red', 'green', 'blue', 'magenta'])\n",
    "    plt.ylabel('Memory (MB)')\n",
    "    plt.title('Average GPU Memory Usage by Stage')\n",
    "    \n",
    "    # Add values on top of bars\n",
    "    for i, v in enumerate(memory_values):\n",
    "        plt.text(i, v + 50, f\"{v:.2f} MB\", ha='center')\n",
    "    \n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"memory_by_stage.png\")\n",
    "    print(\"Memory by stage plot saved to memory_by_stage.png\")\n",
    "\n",
    "def main():\n",
    "    # Run memory analysis\n",
    "    results = measure_model_memory(\n",
    "        model_path=CFG.qwen_model_path,\n",
    "        test_image_path=CFG.test_image_path,\n",
    "        num_runs=CFG.num_runs,\n",
    "        max_tokens=CFG.max_tokens\n",
    "    )\n",
    "    \n",
    "    # Save results\n",
    "    with open(CFG.output_file, 'w') as f:\n",
    "        # Need to convert some types that aren't JSON serializable\n",
    "        cleaned_results = json.loads(\n",
    "            json.dumps(results, default=lambda o: str(o) if isinstance(o, (torch.device, type)) else o)\n",
    "        )\n",
    "        json.dump(cleaned_results, f, indent=2)\n",
    "    \n",
    "    print(f\"Results saved to {CFG.output_file}\")\n",
    "    \n",
    "    # Plot results\n",
    "    if 'runs' in results and results['runs']:\n",
    "        plot_memory_usage(results)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T05:19:44.719780Z",
     "iopub.status.busy": "2025-05-21T05:19:44.719379Z",
     "iopub.status.idle": "2025-05-21T05:19:51.308740Z",
     "shell.execute_reply": "2025-05-21T05:19:51.307787Z",
     "shell.execute_reply.started": "2025-05-21T05:19:44.719754Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.1.8)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (4.67.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->rouge_score) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->rouge_score) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->rouge_score) (2024.2.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=eb1eeb612cc628bd70e519c450054fab0d355ff89aca69904a2d8cc2293def27\n",
      "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T05:19:51.310802Z",
     "iopub.status.busy": "2025-05-21T05:19:51.310561Z",
     "iopub.status.idle": "2025-05-21T05:30:45.866912Z",
     "shell.execute_reply": "2025-05-21T05:30:45.866109Z",
     "shell.execute_reply.started": "2025-05-21T05:19:51.310778Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model from: /kaggle/input/qwen2-vl/transformers/7b-instruct/1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-21 05:20:05.307352: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747804805.539601      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747804805.606827      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fb1bf00c5804eb0a9f7762e7e8fe640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on device: cuda:0\n",
      "\n",
      "==================================================\n",
      "Processing Receipts dataset from /kaggle/input/handwritten-data-form-receipts/receipts/receipts\n",
      "==================================================\n",
      "Found 5 image-txt pairs\n",
      "\n",
      "Processing 1/5: image2\n",
      "Loaded image: /kaggle/input/handwritten-data-form-receipts/receipts/receipts/image2.jpg, size: (517, 748)\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all text from this receipt image. Include store name, items, prices, and totals and all the details p...\n",
      "\n",
      "Ground Truth Preview:\n",
      "9th January 1939\n",
      "\n",
      "Mrs E. Martin\n",
      "No. 8\n",
      "Dr. to A. Murphy,\n",
      "\n",
      "2 weeks rent of cottage No. 8\n",
      "from 7th to 21st Jan 39 @ 35/-    3  10  0\n",
      "Sanitary fee        ...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.5745\n",
      "ROUGE-2: 0.3871\n",
      "ROUGE-L: 0.5426\n",
      "\n",
      "Processing 2/5: image1\n",
      "Loaded image: /kaggle/input/handwritten-data-form-receipts/receipts/receipts/image1.jpg, size: (400, 532)\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all text from this receipt image. Include store name, items, prices, and totals and all the details p...\n",
      "\n",
      "Ground Truth Preview:\n",
      "Date 19\n",
      "A PHOTOGRAPHER'S PLACE\n",
      "133 MERCER STREET\n",
      "NEW YORK, N.Y. 10012\n",
      "M No. Clerk Reg. No. \n",
      "\n",
      "1.8/5/98\n",
      "2\n",
      "3 FLORA 85\n",
      "4 (3) PRINTS 10\n",
      "5\n",
      "6\n",
      "7 TAX 7 85\n",
      "8\n",
      "9\n",
      "...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.2254\n",
      "ROUGE-2: 0.1108\n",
      "ROUGE-L: 0.1631\n",
      "\n",
      "Processing 3/5: image4\n",
      "Loaded image: /kaggle/input/handwritten-data-form-receipts/receipts/receipts/image4.png, size: (850, 996)\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all text from this receipt image. Include store name, items, prices, and totals and all the details p...\n",
      "\n",
      "Ground Truth Preview:\n",
      "MEDICAL BILL RECEIPT\n",
      "Receipt Number #14586\n",
      "Date 1011212020\n",
      "Name of Medical Institution: Clinic Yap\n",
      "Practitioner Name: Yap Chang Chui\n",
      "License Number: -...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.8085\n",
      "ROUGE-2: 0.7639\n",
      "ROUGE-L: 0.7915\n",
      "\n",
      "Processing 4/5: image3\n",
      "Loaded image: /kaggle/input/handwritten-data-form-receipts/receipts/receipts/image3.png, size: (924, 601)\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all text from this receipt image. Include store name, items, prices, and totals and all the details p...\n",
      "\n",
      "Ground Truth Preview:\n",
      "RECEIPT\n",
      "\n",
      "Payer: Annie Greens\n",
      "Payee: ABC Furniture Co\n",
      "Address: 5 Any Street\n",
      "Good Suburb\n",
      "Forrest Town X2204Y\n",
      "\n",
      "Address: 101 Tree Store\n",
      "Leafy Vale\n",
      "Forrest...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.6296\n",
      "ROUGE-2: 0.4500\n",
      "ROUGE-L: 0.5062\n",
      "\n",
      "Processing 5/5: image5\n",
      "Loaded image: /kaggle/input/handwritten-data-form-receipts/receipts/receipts/image5.jpg, size: (720, 1203)\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all text from this receipt image. Include store name, items, prices, and totals and all the details p...\n",
      "\n",
      "Ground Truth Preview:\n",
      "WILLIAMS' BOOK STORE\n",
      "Established 1908\n",
      "708 SOUTH PACIFIC AVENUE\n",
      "San Pedro, Calif. 90731\n",
      "832-3631\n",
      "\n",
      "Date 2/21/1981\n",
      "\n",
      "Name Ellen Leonard\n",
      "Address 1351 W 15t...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.7375\n",
      "ROUGE-2: 0.5949\n",
      "ROUGE-L: 0.7000\n",
      "\n",
      "Dataset processing complete. Results saved to ./qwen_results/qwen_receipt_results.json\n",
      "\n",
      "Average ROUGE Scores:\n",
      "  ROUGE-1: 0.5951\n",
      "  ROUGE-2: 0.4614\n",
      "  ROUGE-L: 0.5407\n",
      "Average inference time: 38.67 seconds\n",
      "\n",
      "==================================================\n",
      "Processing Forms dataset from /kaggle/input/handwritten-data-form-receipts/forms/forms\n",
      "==================================================\n",
      "Found 5 image-txt pairs\n",
      "\n",
      "Processing 1/5: image6\n",
      "Loaded image: /kaggle/input/handwritten-data-form-receipts/forms/forms/image6.jpg, size: (846, 1100)\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all text from this form image.It is the mediacl registration form of a hospital Include all name, eme...\n",
      "\n",
      "Ground Truth Preview:\n",
      "Hospital Patient Registration Form\n",
      "Please fill out this form accurately. All information is confidential.\n",
      "\n",
      "Full Name: Virat Vaibhav\n",
      "Date of Birth (DD/...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.7601\n",
      "ROUGE-2: 0.7147\n",
      "ROUGE-L: 0.7601\n",
      "\n",
      "Processing 2/5: image9\n",
      "Loaded image: /kaggle/input/handwritten-data-form-receipts/forms/forms/image9.jpg, size: (830, 1100)\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all text from this form image.It is the mediacl registration form of a hospital Include all name, eme...\n",
      "\n",
      "Ground Truth Preview:\n",
      "Hospital Patient Registration Form\n",
      "Please fill out this form accurately. All information is confidential.\n",
      "\n",
      "Full Name: Anant Rajput\n",
      "Date of Birth (DD/M...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.7768\n",
      "ROUGE-2: 0.7446\n",
      "ROUGE-L: 0.7768\n",
      "\n",
      "Processing 3/5: image8\n",
      "Loaded image: /kaggle/input/handwritten-data-form-receipts/forms/forms/image8.jpg, size: (809, 1100)\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all text from this form image.It is the mediacl registration form of a hospital Include all name, eme...\n",
      "\n",
      "Ground Truth Preview:\n",
      "Hospital Patient Registration Form\n",
      "Please fill out this form accurately. All information is confidential.\n",
      "\n",
      "Full Name: Prachi Singh\n",
      "Date of Birth (DD/M...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.7802\n",
      "ROUGE-2: 0.7664\n",
      "ROUGE-L: 0.7802\n",
      "\n",
      "Processing 4/5: image10\n",
      "Loaded image: /kaggle/input/handwritten-data-form-receipts/forms/forms/image10.jpg, size: (850, 1091)\n",
      "Running OCR extraction...\n",
      "\n",
      "OCR Result Preview:\n",
      "system\n",
      "You are a helpful assistant.\n",
      "user\n",
      "Extract all text from this form image.It is the mediacl registration form of a hospital Include all name, eme...\n",
      "\n",
      "Ground Truth Preview:\n",
      "Hospital Patient Registration Form\n",
      "Please fill out this form accurately. All information is confidential.\n",
      "\n",
      "Full Name: Kartik Bairwa\n",
      "Date of Birth (DD/...\n",
      "\n",
      "Calculating ROUGE scores...\n",
      "ROUGE-1: 0.7500\n",
      "ROUGE-2: 0.7107\n",
      "ROUGE-L: 0.7500\n",
      "\n",
      "Dataset processing complete. Results saved to ./qwen_results/qwen_form_results.json\n",
      "\n",
      "Average ROUGE Scores:\n",
      "  ROUGE-1: 0.7634\n",
      "  ROUGE-2: 0.7269\n",
      "  ROUGE-L: 0.7634\n",
      "Average inference time: 46.49 seconds\n",
      "\n",
      "Comparison summary saved to ./qwen_results/qwen_summary.json\n",
      "\n",
      "Dataset Comparison:\n",
      "               Metric Receipts   Forms Better Dataset Difference %\n",
      "0             ROUGE-1   0.5951  0.7634          Forms       22.05%\n",
      "1             ROUGE-2   0.4614  0.7269          Forms       36.53%\n",
      "2             ROUGE-L   0.5407  0.7634          Forms       29.18%\n",
      "3  Inference Time (s)    38.67   46.49       Receipts       16.82%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance\n",
    "from rouge_score import rouge_scorer\n",
    "import re\n",
    "import subprocess\n",
    "import psutil\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration class\n",
    "class CFG:\n",
    "    # Model\n",
    "    model_name = \"/kaggle/input/qwen2-vl/transformers/7b-instruct/1\"\n",
    "    max_tokens = 1024\n",
    "    contrast_factor = 2.0  # Enhance image contrast\n",
    "    \n",
    "    # Dataset paths\n",
    "    receipt_dir = \"/kaggle/input/handwritten-data-form-receipts/receipts/receipts\"  # Folder with receipt images and txt files\n",
    "    form_dir = \"/kaggle/input/handwritten-data-form-receipts/forms/forms\"        # Folder with form images and txt files\n",
    "    \n",
    "    # Output data\n",
    "    output_dir = \"./qwen_results\"\n",
    "    receipt_output = \"qwen_receipt_results.json\"\n",
    "    form_output = \"qwen_form_results.json\"\n",
    "    summary_output = \"qwen_summary.json\"\n",
    "    \n",
    "    # Image formats to process\n",
    "    img_extensions = ['.jpg', '.jpeg', '.png', '.tif', '.tiff']\n",
    "\n",
    "def get_memory_usage():\n",
    "    \"\"\"Get current memory usage of the process\"\"\"\n",
    "    try:\n",
    "        process = psutil.Process(os.getpid())\n",
    "        memory_info = process.memory_info()\n",
    "        return {\n",
    "            'rss': memory_info.rss / (1024 * 1024),  # RSS in MB\n",
    "            'vms': memory_info.vms / (1024 * 1024)   # VMS in MB\n",
    "        }\n",
    "    except:\n",
    "        return {'rss': 0, 'vms': 0}\n",
    "\n",
    "def get_cuda_memory_usage():\n",
    "    \"\"\"Get CUDA memory usage using torch\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return {\n",
    "            'allocated': torch.cuda.memory_allocated() / (1024 * 1024),  # MB\n",
    "            'reserved': torch.cuda.memory_reserved() / (1024 * 1024),    # MB\n",
    "            'max_allocated': torch.cuda.max_memory_allocated() / (1024 * 1024)  # MB\n",
    "        }\n",
    "    return None\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"Build Qwen-2-VL model\"\"\"\n",
    "    print(f'\\nLoading model from: {CFG.model_name}\\n')\n",
    "    \n",
    "    # Import required modules\n",
    "    from transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n",
    "    \n",
    "    # Load model and processor\n",
    "    model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
    "        CFG.model_name,\n",
    "        torch_dtype=\"auto\",\n",
    "        device_map=\"auto\",\n",
    "    )\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(CFG.model_name)\n",
    "    \n",
    "    device = next(model.parameters()).device\n",
    "    print(f\"Model loaded successfully on device: {device}\")\n",
    "    \n",
    "    return processor, model\n",
    "\n",
    "def inference(image, model, processor, prompt_text=\"Extract all the text from this image.\"):\n",
    "    \"\"\"Run inference with Qwen-2-VL model\"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Record metrics before inference\n",
    "    metrics_before = {\n",
    "        'memory': get_memory_usage(),\n",
    "        'cuda': get_cuda_memory_usage(),\n",
    "        'timestamp': time.time()\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Enhance image contrast\n",
    "        enhanced_image = ImageEnhance.Contrast(image).enhance(CFG.contrast_factor).convert(\"RGB\")\n",
    "        \n",
    "        # Create messages for the model\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\"},\n",
    "                    {\"type\": \"text\", \"text\": prompt_text}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        # Process input\n",
    "        inputs = processor(\n",
    "            text=processor.apply_chat_template(messages, add_generation_prompt=True),\n",
    "            images=[enhanced_image],\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        # Move inputs to device\n",
    "        inputs = inputs.to(model.device)\n",
    "        \n",
    "        # Generate output\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(**inputs, max_new_tokens=CFG.max_tokens)\n",
    "        \n",
    "        # Decode output\n",
    "        extracted_text = processor.batch_decode(\n",
    "            output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True\n",
    "        )[0]\n",
    "        \n",
    "        # Extract only the model's response (remove prompts)\n",
    "        try:\n",
    "            # Check if there's an \"ASSISTANT:\" prefix in the output\n",
    "            if \"ASSISTANT:\" in extracted_text:\n",
    "                result = extracted_text.split(\"ASSISTANT:\", 1)[1].strip()\n",
    "            else:\n",
    "                result = extracted_text\n",
    "        except:\n",
    "            result = extracted_text\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during inference: {str(e)}\")\n",
    "        result = f\"Error: {str(e)}\"\n",
    "    \n",
    "    # Record metrics after inference\n",
    "    metrics_after = {\n",
    "        'memory': get_memory_usage(),\n",
    "        'cuda': get_cuda_memory_usage(),\n",
    "        'timestamp': time.time()\n",
    "    }\n",
    "    \n",
    "    # Calculate runtime\n",
    "    inference_time = metrics_after['timestamp'] - metrics_before['timestamp']\n",
    "    \n",
    "    # Clear CUDA cache\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    # Return results and metrics\n",
    "    return {\n",
    "        'result': result,\n",
    "        'metrics': {\n",
    "            'before': metrics_before,\n",
    "            'after': metrics_after,\n",
    "            'inference_time': inference_time\n",
    "        }\n",
    "    }\n",
    "\n",
    "def load_annotation_from_txt(txt_path):\n",
    "    \"\"\"Load annotation from a text file\"\"\"\n",
    "    try:\n",
    "        with open(txt_path, 'r', encoding='utf-8') as f:\n",
    "            return f.read().strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading annotation file {txt_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Normalize text for better ROUGE matching\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Replace multiple spaces with single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Remove non-alphanumeric chars except spaces\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    # Trim leading/trailing spaces\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def calculate_rouge_scores(predicted_text, reference_text):\n",
    "    \"\"\"Calculate ROUGE scores between prediction and reference\"\"\"\n",
    "    # Initialize the ROUGE scorer\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    \n",
    "    # Normalize texts\n",
    "    normalized_reference = normalize_text(reference_text)\n",
    "    normalized_prediction = normalize_text(predicted_text)\n",
    "    \n",
    "    # Skip if either text is empty\n",
    "    if not normalized_reference or not normalized_prediction:\n",
    "        return {\n",
    "            'rouge1': 0,\n",
    "            'rouge2': 0,\n",
    "            'rougeL': 0,\n",
    "            'debug': {\n",
    "                'reference_empty': not normalized_reference,\n",
    "                'prediction_empty': not normalized_prediction\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    # Calculate scores\n",
    "    scores = scorer.score(normalized_reference, normalized_prediction)\n",
    "    \n",
    "    # Debug info\n",
    "    debug_info = {\n",
    "        'reference_sample': normalized_reference[:100] + \"...\" if len(normalized_reference) > 100 else normalized_reference,\n",
    "        'prediction_sample': normalized_prediction[:100] + \"...\" if len(normalized_prediction) > 100 else normalized_prediction,\n",
    "        'reference_length': len(normalized_reference),\n",
    "        'prediction_length': len(normalized_prediction)\n",
    "    }\n",
    "    \n",
    "    return {\n",
    "        'rouge1': scores['rouge1'].fmeasure,\n",
    "        'rouge2': scores['rouge2'].fmeasure,\n",
    "        'rougeL': scores['rougeL'].fmeasure,\n",
    "        'debug': debug_info\n",
    "    }\n",
    "\n",
    "def find_image_txt_pairs(directory):\n",
    "    \"\"\"Find matching image and txt files in a directory\"\"\"\n",
    "    # Get all files\n",
    "    all_files = os.listdir(directory)\n",
    "    \n",
    "    # Find image files\n",
    "    image_files = [f for f in all_files if any(f.lower().endswith(ext) for ext in CFG.img_extensions)]\n",
    "    \n",
    "    # Find matching txt files\n",
    "    pairs = []\n",
    "    for img_file in image_files:\n",
    "        base_name = os.path.splitext(img_file)[0]\n",
    "        txt_file = f\"{base_name}.txt\"\n",
    "        \n",
    "        if txt_file in all_files:\n",
    "            pairs.append({\n",
    "                'image': os.path.join(directory, img_file),\n",
    "                'txt': os.path.join(directory, txt_file),\n",
    "                'base_name': base_name\n",
    "            })\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "def process_dataset(dataset_dir, output_file, model, processor, dataset_name):\n",
    "    \"\"\"Process a single dataset (receipts or forms)\"\"\"\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing {dataset_name} dataset from {dataset_dir}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Find image-txt pairs\n",
    "    pairs = find_image_txt_pairs(dataset_dir)\n",
    "    print(f\"Found {len(pairs)} image-txt pairs\")\n",
    "    \n",
    "    if len(pairs) == 0:\n",
    "        print(f\"No valid pairs found in {dataset_dir}\")\n",
    "        return None\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Process each pair\n",
    "    for i, pair in enumerate(pairs):\n",
    "        print(f\"\\nProcessing {i+1}/{len(pairs)}: {pair['base_name']}\")\n",
    "        \n",
    "        # Load image\n",
    "        try:\n",
    "            image = Image.open(pair['image'])\n",
    "            print(f\"Loaded image: {pair['image']}, size: {image.size}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {pair['image']}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Load annotation\n",
    "        ground_truth = load_annotation_from_txt(pair['txt'])\n",
    "        if not ground_truth:\n",
    "            print(f\"Empty or invalid annotation file: {pair['txt']}\")\n",
    "            continue\n",
    "        \n",
    "        # Use different prompt based on dataset type\n",
    "        if 'receipt' in dataset_name.lower():\n",
    "            prompt_text = \"Extract all text from this receipt image. Include store name, items, prices, and totals and all the details present in the receipts.\"\n",
    "        else:  # form\n",
    "            prompt_text = \"Extract all text from this form image.It is the mediacl registration form of a hospital Include all name , emergency contact , medical history patient personal info etc.\"\n",
    "        \n",
    "        # Run inference\n",
    "        print(\"Running OCR extraction...\")\n",
    "        ocr_result = inference(image=image, model=model, processor=processor, prompt_text=prompt_text)\n",
    "        \n",
    "        # Print OCR result preview\n",
    "        print(\"\\nOCR Result Preview:\")\n",
    "        preview = ocr_result['result'][:150] + \"...\" if len(ocr_result['result']) > 150 else ocr_result['result']\n",
    "        print(preview)\n",
    "        \n",
    "        # Ground truth preview\n",
    "        print(\"\\nGround Truth Preview:\")\n",
    "        gt_preview = ground_truth[:150] + \"...\" if len(ground_truth) > 150 else ground_truth\n",
    "        print(gt_preview)\n",
    "        \n",
    "        # Calculate ROUGE scores\n",
    "        print(\"\\nCalculating ROUGE scores...\")\n",
    "        rouge_scores = calculate_rouge_scores(ocr_result['result'], ground_truth)\n",
    "        \n",
    "        print(f\"ROUGE-1: {rouge_scores['rouge1']:.4f}\")\n",
    "        print(f\"ROUGE-2: {rouge_scores['rouge2']:.4f}\")\n",
    "        print(f\"ROUGE-L: {rouge_scores['rougeL']:.4f}\")\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'filename': pair['base_name'],\n",
    "            'image_path': pair['image'],\n",
    "            'txt_path': pair['txt'],\n",
    "            'ocr_result': ocr_result['result'],\n",
    "            'ground_truth': ground_truth,\n",
    "            'rouge_scores': rouge_scores,\n",
    "            'inference_time': ocr_result['metrics']['inference_time']\n",
    "        })\n",
    "        \n",
    "        # Save intermediate results\n",
    "        os.makedirs(CFG.output_dir, exist_ok=True)\n",
    "        with open(os.path.join(CFG.output_dir, output_file), 'w') as f:\n",
    "            json.dump({\n",
    "                'model': CFG.model_name,\n",
    "                'dataset': dataset_name,\n",
    "                'results': results\n",
    "            }, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nDataset processing complete. Results saved to {os.path.join(CFG.output_dir, output_file)}\")\n",
    "    \n",
    "    # Calculate average scores\n",
    "    if results:\n",
    "        avg_rouge1 = sum(r['rouge_scores']['rouge1'] for r in results) / len(results)\n",
    "        avg_rouge2 = sum(r['rouge_scores']['rouge2'] for r in results) / len(results)\n",
    "        avg_rougeL = sum(r['rouge_scores']['rougeL'] for r in results) / len(results)\n",
    "        avg_time = sum(r['inference_time'] for r in results) / len(results)\n",
    "        \n",
    "        summary = {\n",
    "            'dataset': dataset_name,\n",
    "            'num_images': len(results),\n",
    "            'avg_rouge1': avg_rouge1,\n",
    "            'avg_rouge2': avg_rouge2,\n",
    "            'avg_rougeL': avg_rougeL,\n",
    "            'avg_inference_time': avg_time\n",
    "        }\n",
    "        \n",
    "        print(\"\\nAverage ROUGE Scores:\")\n",
    "        print(f\"  ROUGE-1: {avg_rouge1:.4f}\")\n",
    "        print(f\"  ROUGE-2: {avg_rouge2:.4f}\")\n",
    "        print(f\"  ROUGE-L: {avg_rougeL:.4f}\")\n",
    "        print(f\"Average inference time: {avg_time:.2f} seconds\")\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    return None\n",
    "\n",
    "def visualize_results(receipt_results, form_results):\n",
    "    \"\"\"Create visualizations comparing performance on both datasets\"\"\"\n",
    "    os.makedirs(CFG.output_dir, exist_ok=True)\n",
    "    \n",
    "    if not receipt_results or not form_results:\n",
    "        print(\"Not enough data to create visualizations\")\n",
    "        return\n",
    "    \n",
    "    # Extract metrics\n",
    "    datasets = ['Receipts', 'Forms']\n",
    "    rouge1_scores = [receipt_results['avg_rouge1'], form_results['avg_rouge1']]\n",
    "    rouge2_scores = [receipt_results['avg_rouge2'], form_results['avg_rouge2']]\n",
    "    rougeL_scores = [receipt_results['avg_rougeL'], form_results['avg_rougeL']]\n",
    "    inf_times = [receipt_results['avg_inference_time'], form_results['avg_inference_time']]\n",
    "    \n",
    "    # Create ROUGE scores comparison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    x = np.arange(len(datasets))\n",
    "    width = 0.25\n",
    "    \n",
    "    plt.bar(x - width, rouge1_scores, width, label='ROUGE-1', color='#2196F3')\n",
    "    plt.bar(x, rouge2_scores, width, label='ROUGE-2', color='#4CAF50')\n",
    "    plt.bar(x + width, rougeL_scores, width, label='ROUGE-L', color='#FFC107')\n",
    "    \n",
    "    plt.xlabel('Datasets')\n",
    "    plt.ylabel('ROUGE Score')\n",
    "    plt.title('Qwen-2-VL Performance on Different Datasets')\n",
    "    plt.xticks(x, datasets)\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.legend()\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add values on top of bars\n",
    "    for i, model_idx in enumerate(x):\n",
    "        plt.text(model_idx - width, rouge1_scores[i] + 0.02, f\"{rouge1_scores[i]:.3f}\", \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "        plt.text(model_idx, rouge2_scores[i] + 0.02, f\"{rouge2_scores[i]:.3f}\", \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "        plt.text(model_idx + width, rougeL_scores[i] + 0.02, f\"{rougeL_scores[i]:.3f}\", \n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(CFG.output_dir, 'dataset_comparison.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Create inference time comparison\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.bar(datasets, inf_times, color=['#2196F3', '#4CAF50'])\n",
    "    plt.xlabel('Datasets')\n",
    "    plt.ylabel('Average Inference Time (seconds)')\n",
    "    plt.title('Inference Time Comparison')\n",
    "    \n",
    "    # Add values on top of bars\n",
    "    for i, time in enumerate(inf_times):\n",
    "        plt.text(i, time + 0.1, f\"{time:.2f}s\", ha='center', va='bottom')\n",
    "    \n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(CFG.output_dir, 'inference_time_comparison.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Return file paths for reporting\n",
    "    return {\n",
    "        'rouge_comparison': os.path.join(CFG.output_dir, 'dataset_comparison.png'),\n",
    "        'time_comparison': os.path.join(CFG.output_dir, 'inference_time_comparison.png')\n",
    "    }\n",
    "\n",
    "def create_comparison_table(receipt_summary, form_summary):\n",
    "    \"\"\"Create a comparison table for the two datasets\"\"\"\n",
    "    if not receipt_summary or not form_summary:\n",
    "        return None\n",
    "    \n",
    "    # Determine which dataset performs better for each metric\n",
    "    better_dataset = {\n",
    "        'rouge1': 'Receipts' if receipt_summary['avg_rouge1'] > form_summary['avg_rouge1'] else 'Forms',\n",
    "        'rouge2': 'Receipts' if receipt_summary['avg_rouge2'] > form_summary['avg_rouge2'] else 'Forms',\n",
    "        'rougeL': 'Receipts' if receipt_summary['avg_rougeL'] > form_summary['avg_rougeL'] else 'Forms',\n",
    "        'time': 'Receipts' if receipt_summary['avg_inference_time'] < form_summary['avg_inference_time'] else 'Forms'\n",
    "    }\n",
    "    \n",
    "    # Calculate percentage difference\n",
    "    diff_percent = {\n",
    "        'rouge1': abs(receipt_summary['avg_rouge1'] - form_summary['avg_rouge1']) / \n",
    "                 max(receipt_summary['avg_rouge1'], form_summary['avg_rouge1']) * 100,\n",
    "        'rouge2': abs(receipt_summary['avg_rouge2'] - form_summary['avg_rouge2']) / \n",
    "                 max(receipt_summary['avg_rouge2'], form_summary['avg_rouge2']) * 100,\n",
    "        'rougeL': abs(receipt_summary['avg_rougeL'] - form_summary['avg_rougeL']) / \n",
    "                 max(receipt_summary['avg_rougeL'], form_summary['avg_rougeL']) * 100,\n",
    "        'time': abs(receipt_summary['avg_inference_time'] - form_summary['avg_inference_time']) / \n",
    "               max(receipt_summary['avg_inference_time'], form_summary['avg_inference_time']) * 100\n",
    "    }\n",
    "    \n",
    "    # Create DataFrame for the table\n",
    "    df = pd.DataFrame({\n",
    "        'Metric': ['ROUGE-1', 'ROUGE-2', 'ROUGE-L', 'Inference Time (s)'],\n",
    "        'Receipts': [\n",
    "            f\"{receipt_summary['avg_rouge1']:.4f}\",\n",
    "            f\"{receipt_summary['avg_rouge2']:.4f}\",\n",
    "            f\"{receipt_summary['avg_rougeL']:.4f}\",\n",
    "            f\"{receipt_summary['avg_inference_time']:.2f}\"\n",
    "        ],\n",
    "        'Forms': [\n",
    "            f\"{form_summary['avg_rouge1']:.4f}\",\n",
    "            f\"{form_summary['avg_rouge2']:.4f}\",\n",
    "            f\"{form_summary['avg_rougeL']:.4f}\",\n",
    "            f\"{form_summary['avg_inference_time']:.2f}\"\n",
    "        ],\n",
    "        'Better Dataset': [\n",
    "            better_dataset['rouge1'],\n",
    "            better_dataset['rouge2'],\n",
    "            better_dataset['rougeL'],\n",
    "            better_dataset['time']\n",
    "        ],\n",
    "        'Difference %': [\n",
    "            f\"{diff_percent['rouge1']:.2f}%\",\n",
    "            f\"{diff_percent['rouge2']:.2f}%\",\n",
    "            f\"{diff_percent['rougeL']:.2f}%\",\n",
    "            f\"{diff_percent['time']:.2f}%\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Save to CSV\n",
    "    csv_path = os.path.join(CFG.output_dir, 'dataset_comparison.csv')\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Also save as markdown table\n",
    "    md_table = df.to_markdown(index=False)\n",
    "    with open(os.path.join(CFG.output_dir, 'dataset_comparison.md'), 'w') as f:\n",
    "        f.write(md_table)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def main():\n",
    "    # Create output directory\n",
    "    os.makedirs(CFG.output_dir, exist_ok=True)\n",
    "    \n",
    "    # Build model once\n",
    "    processor, model = build_model()\n",
    "    \n",
    "    # Process receipt dataset\n",
    "    receipt_summary = process_dataset(\n",
    "        dataset_dir=CFG.receipt_dir,\n",
    "        output_file=CFG.receipt_output,\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        dataset_name=\"Receipts\"\n",
    "    )\n",
    "    \n",
    "    # Process form dataset\n",
    "    form_summary = process_dataset(\n",
    "        dataset_dir=CFG.form_dir,\n",
    "        output_file=CFG.form_output,\n",
    "        model=model,\n",
    "        processor=processor,\n",
    "        dataset_name=\"Forms\"\n",
    "    )\n",
    "    \n",
    "    # Create visualizations\n",
    "    if receipt_summary and form_summary:\n",
    "        chart_paths = visualize_results(receipt_summary, form_summary)\n",
    "        \n",
    "        # Create comparison table\n",
    "        comparison_table = create_comparison_table(receipt_summary, form_summary)\n",
    "        \n",
    "        # Save combined summary\n",
    "        combined_summary = {\n",
    "            'model': CFG.model_name,\n",
    "            'receipts': receipt_summary,\n",
    "            'forms': form_summary,\n",
    "            'charts': chart_paths\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(CFG.output_dir, CFG.summary_output), 'w') as f:\n",
    "            json.dump(combined_summary, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nComparison summary saved to {os.path.join(CFG.output_dir, CFG.summary_output)}\")\n",
    "        print(\"\\nDataset Comparison:\")\n",
    "        print(comparison_table)\n",
    "    else:\n",
    "        print(\"\\nCould not create comparison - one or both datasets failed to process\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-21T05:31:54.584683Z",
     "iopub.status.busy": "2025-05-21T05:31:54.584063Z",
     "iopub.status.idle": "2025-05-21T05:31:54.763732Z",
     "shell.execute_reply": "2025-05-21T05:31:54.762785Z",
     "shell.execute_reply.started": "2025-05-21T05:31:54.584658Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/qwen_results/ (stored 0%)\n",
      "  adding: kaggle/working/qwen_results/dataset_comparison.md (deflated 61%)\n",
      "  adding: kaggle/working/qwen_results/dataset_comparison.png (deflated 23%)\n",
      "  adding: kaggle/working/qwen_results/qwen_receipt_results.json (deflated 70%)\n",
      "  adding: kaggle/working/qwen_results/inference_time_comparison.png (deflated 20%)\n",
      "  adding: kaggle/working/qwen_results/qwen_form_results.json (deflated 85%)\n",
      "  adding: kaggle/working/qwen_results/dataset_comparison.csv (deflated 29%)\n",
      "  adding: kaggle/working/qwen_results/qwen_summary.json (deflated 55%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!zip -r qwen_handwritten /kaggle/working/qwen_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 3753245,
     "sourceId": 6494011,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7470279,
     "sourceId": 11885614,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7474335,
     "sourceId": 11891525,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 170434,
     "modelInstanceId": 147946,
     "sourceId": 173805,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
